{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "#import essential functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import gymnasium as gym\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#set all random seeds\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Small epsilon value for stabilizing division operations\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "\n",
    "import os\n",
    "os.environ['PYDEVD_WARN_SLOW_RESOLVE_TIMEOUT'] = '2.0'  # set timeout to 2 seconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "Student Name: Ji Zhou Wang\n",
    "Student ID: 260518646\n",
    "\n",
    "Student Name:\n",
    "Student ID:\n",
    "\n",
    "Student Name:\n",
    "Student ID:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define epsilon-greedy policy\n",
    "def epsilon_greedy(QF, state, num_actions, epsilon):\n",
    "    if np.random.uniform() < epsilon:\n",
    "        # Choose a random action with probability epsilon\n",
    "        return np.random.choice(num_actions)\n",
    "    else:\n",
    "        # Choose the action with highest Q-value for the current state\n",
    "        return np.argmax(QF[state, :])\n",
    "\n",
    "#define uniform random policy\n",
    "def uniform_random(num_actions):\n",
    "    return np.random.choice(num_actions)\n",
    "\n",
    "#define softmax boltzmann policy\n",
    "def softmax_boltzmann(Q, state, num_actions, temperature):\n",
    "    # Calculate the probabilities using the softmax function\n",
    "    probs = softmax(Q[state, :] / temperature)\n",
    "    # Choose an action using the calculated probabilities\n",
    "    return np.random.choice(num_actions, p=probs)\n",
    "\n",
    "# Define the softmax function prevent overflow\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneHotEncoder for state and action function approximation representation\n",
    "#Also includes Q-learning algorithm with epsilon greedy policy\n",
    "class OneHotFA:\n",
    "    def __init__(self, env, num_bins, actor_weights = None, critic_weights = None):\n",
    "        self.env = env\n",
    "        self.num_bins = num_bins\n",
    "        self.num_states = env.observation_space.shape[0]\n",
    "        self.num_actions = env.action_space.n\n",
    "        self.bins = self.get_bins()\n",
    "        self.num_features = self.num_bins ** self.num_states\n",
    "        self.init_actor_weights = actor_weights\n",
    "        self.init_critic_weights = critic_weights\n",
    "        if actor_weights is None: \n",
    "            #intialize the starting weights randomly between -0.001 and 0.001 for each feature and action\n",
    "            self.actor_weights = np.random.uniform(-0.001, 0.001, (self.num_features, self.num_actions))\n",
    "        else:\n",
    "            self.actor_weights = actor_weights\n",
    "        \n",
    "        if critic_weights is None:\n",
    "            #initialize critic weights\n",
    "            self.critic_weights = np.random.uniform(-0.001, 0.001, self.num_features)\n",
    "        else:\n",
    "            self.critic_weights = critic_weights\n",
    "\n",
    "    #print all the parameters of the class\n",
    "    def print_params(self):\n",
    "        print(\"num_bins: \" + str(self.num_bins))\n",
    "        print(\"num_states: \" + str(self.num_states))\n",
    "        print(\"num_actions: \" + str(self.num_actions))\n",
    "        print(\"bins: \" + str(self.bins))\n",
    "        print(\"num_features: \" + str(self.num_features))\n",
    "        print(\"weights: \" + str(self.actor_weights))\n",
    "        print(\"critic_weights: \" + str(self.critic_weights))\n",
    "\n",
    "    #get the bins for each state\n",
    "    def get_bins(self):\n",
    "        # compute the bin sizes for position and angle\n",
    "        # cart_pos_binsize = (self.env.observation_space.high[0] - self.env.observation_space.low[0]) / self.num_bins\n",
    "        # pole_angle_binsize = (self.env.observation_space.high[2] - self.env.observation_space.low[2]) / self.num_bins\n",
    "\n",
    "        cart_pos_bin = np.linspace(self.env.observation_space.low[0], self.env.observation_space.high[0], self.num_bins+1)\n",
    "        pole_angle_bin = np.linspace(self.env.observation_space.low[2], self.env.observation_space.high[2], self.num_bins+1)\n",
    "        # compute the bins for cart velocity and pole angle velocity\n",
    "        # calculated from sampling experiment (sd/3)\n",
    "        cart_vel_bin = [-np.inf, -0.62, -0.46, -0.31, -0.15, 0.0, 0.15, 0.31, 0.46, 0.62, np.inf]\n",
    "        pole_vel_bin = [-np.inf, -0.99, -0.74, -0.49, -0.24, 0.0, 0.24, 0.49, 0.74, 0.99, np.inf]\n",
    "\n",
    "        #(sd/2)\n",
    "        #cart_vel_bin = [-np.inf, -0.93, -0.70, -0.46, -0.23, 0.0, 0.23, 0.46, 0.70, 0.93, np.inf]\n",
    "        #pole_vel_bin = [-np.inf, -1.49, -1.11, -0.74, -0.37, 0.0, 0.37, 0.74, 1.11, 1.49, np.inf]\n",
    "\n",
    "\n",
    "        #combine all bins into one array\n",
    "        bins = np.array([cart_pos_bin, cart_vel_bin, pole_angle_bin, pole_vel_bin])\n",
    "        # print(\"bins: \" + str(type(bins)) + \" \" + str(bins.shape))\n",
    "        # print(\"bins: \" + str(bins))\n",
    "        return bins\n",
    "    \n",
    "    #discretize the input state into a one-hot vector of length num_features for each bin in the bins array corresponding to the state value\n",
    "    def discretize_state(self, state):\n",
    "        state_discrete = np.zeros(self.num_features)\n",
    "\n",
    "        #compute the indices of the bin for each state value\n",
    "        state_indices = self.get_state_indices(state)\n",
    "        \n",
    "        #compute the index of the overall state vector\n",
    "        state_index = 0\n",
    "        for i in range(self.num_states):\n",
    "            state_index += (state_indices[i] - 1) * (self.num_bins ** i)\n",
    "        \n",
    "        #assert that the index is within the bounds of the state vector\n",
    "        assert state_index < self.num_features and state_index >= 0\n",
    "\n",
    "        #set the index of the overall state vector to 1 for the given state\n",
    "        state_discrete[state_index] = 1\n",
    "\n",
    "        return state_discrete, state_index\n",
    "\n",
    "    #compute the indices of the bin for each state value\n",
    "    def get_state_indices(self, state):\n",
    "        state_indices = []\n",
    "        for i in range(self.num_states):\n",
    "            state_indices.append(np.digitize(state[i], self.bins[i]))\n",
    "        return state_indices\n",
    "\n",
    "    #compute the Q-value for each action with the current actor weights\n",
    "    def get_Q_actions(self, state_discrete):\n",
    "        Q_actions = np.dot(state_discrete, self.actor_weights)\n",
    "        assert Q_actions.shape == (self.num_actions,)\n",
    "        return Q_actions\n",
    "\n",
    "    #compute the Q-value for the given state and action with the current actor weights\n",
    "    def get_Q_action(self, state_discrete, action):\n",
    "        Q_action = np.dot(state_discrete, self.actor_weights)[action]\n",
    "        return Q_action\n",
    "    \n",
    "    def get_V_critic(self, state_discrete):\n",
    "        V_critic = np.dot(state_discrete, self.critic_weights)\n",
    "        return V_critic\n",
    "    \n",
    "    #update the weights for the state and action with TD(0)\n",
    "    def update_weights(self, state_discrete, state_index, action, reward, alpha = 0.01):\n",
    "        #compute the Q-value for the state and action\n",
    "        Q = self.get_Q_action(state_discrete, action) #can use state index for more efficient computation\n",
    "        #compute the TD(0)-error\n",
    "        td_error = reward - Q\n",
    "        #update the weights\n",
    "        self.actor_weights[state_index,action] += alpha * td_error\n",
    "\n",
    "    #Q-learning algorithm with epsilon-greedy policy\n",
    "    def train_q_learning(self, env, episode_count = 10, alpha=0.5, gamma=0.999, epsilon=0.1, use_decay = False, epsilon_decay=0.999, seed=42):\n",
    "        # Initialize a table to count the rewards for each episode\n",
    "        rewards = np.zeros(episode_count)\n",
    "        # Initialize a table to count the number of steps for each episode\n",
    "        steps = np.zeros(episode_count)\n",
    "    \n",
    "        # Loop over episodes\n",
    "        for ep_step in range(episode_count):\n",
    "            # initialize state and action for current episode\n",
    "            state, info = env.reset(seed=seed) \n",
    "            state_discrete, state_index = self.discretize_state(state)\n",
    "            truncated = False\n",
    "            terminated = False\n",
    "            \n",
    "            # Loop over time steps within the episode\n",
    "            while not (terminated or truncated):\n",
    "\n",
    "                # Choose the next action using epsilon-greedy policy\n",
    "                action = self.epsilon_greedy_FA(epsilon,state_discrete)\n",
    "                # Take the chosen action and observe the next state and reward\n",
    "                next_state, reward, terminated, truncated, info = env.step(action)\n",
    "                # Discretize the next state\n",
    "                next_state_discrete, next_state_index = self.discretize_state(next_state)\n",
    "\n",
    "                # Update the Q-value for the current state and action\n",
    "                target = reward + gamma * np.max(self.get_Q_actions(next_state_discrete))\n",
    "                \n",
    "                # Update the weights for the current state and action\n",
    "                self.update_weights(state_discrete,state_index, action, target, alpha)\n",
    "\n",
    "                # Update the state\n",
    "                state_discrete = next_state_discrete\n",
    "                state_index = next_state_index\n",
    "    \n",
    "                # store the total discounted reward for each episode\n",
    "                rewards[ep_step] += reward * (gamma ** steps[ep_step])\n",
    "    \n",
    "                # store the number of steps for each episode\n",
    "                steps[ep_step] += 1\n",
    "    \n",
    "                env.render()\n",
    "            \n",
    "            # Decay the epsilon\n",
    "            if use_decay:\n",
    "                epsilon *= epsilon_decay\n",
    "    \n",
    "        #return the Q-table and the reward for all episodes\n",
    "        return self.actor_weights, rewards, steps\n",
    "\n",
    "    \n",
    "    # Compute the policy for the given action and state (pi_theta(a,s))\n",
    "    def get_prob_action(self, action, state_discrete, temperature = 1.0):\n",
    "        Q_actions = self.get_Q_actions(state_discrete) #logits\n",
    "        #softmax normalization\n",
    "        softmax = self.softmax(Q_actions / temperature)\n",
    "        #return the probability of the given action\n",
    "        pi = softmax[action]\n",
    "        return pi\n",
    "    \n",
    "    # Choose an action based on the softmax of the Q-values (pi_theta(a,s))\n",
    "    def get_softmax_action(self, state_discrete, temperature=1.0):\n",
    "        Q_actions = self.get_Q_actions(state_discrete)\n",
    "        #softmax normalization\n",
    "        softmax = self.softmax(Q_actions / temperature)         \n",
    "        #choose an action based on the softmax\n",
    "        action = np.random.choice(self.num_actions, p=softmax)\n",
    "        return action\n",
    "\n",
    "    # softmax function\n",
    "    def softmax(self, x):\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum()\n",
    "\n",
    "\n",
    "    #reinitialize the weights uniformly\n",
    "    def reset_weights(self):\n",
    "        if self.init_actor_weights is not None:\n",
    "            self.actor_weights = self.init_actor_weights\n",
    "            #intialize the starting weights randomly between -0.001 and 0.001 for each feature and action\n",
    "        else:\n",
    "            self.actor_weights = np.random.uniform(-0.001, 0.001, (self.num_features, self.num_actions))\n",
    "        \n",
    "        if self.init_critic_weights is not None:\n",
    "            self.critic_weights = self.init_critic_weights\n",
    "        else:\n",
    "            #initialize critic weights\n",
    "            self.critic_weights = np.random.uniform(-0.001, 0.001, self.num_features)\n",
    "\n",
    "    #define epsilon-greedy policy\n",
    "    def epsilon_greedy_FA(self, epsilon, state_discrete):\n",
    "        if np.random.uniform() < epsilon:\n",
    "            # Choose a random action with probability epsilon\n",
    "            return np.random.choice(self.num_actions)\n",
    "        else:\n",
    "            # Choose the action with highest Q-value for the current state\n",
    "            return np.argmax(self.get_Q_actions(state_discrete))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A2C Advantage Actor-Critic agent network\n",
    "#code using snippets from https://gymnasium.farama.org/tutorials/gymnasium_basics/vector_envs_tutorial/\n",
    "\n",
    "class A2C(nn.Module):\n",
    "    \"\"\"\n",
    "    (Synchronous) Advantage Actor-Critic agent class\n",
    "    Args:\n",
    "        n_features: The number of features of the input state.\n",
    "        n_actions: The number of actions the agent can take.\n",
    "        device: The device to run the computations on (running on a GPU might be quicker for larger Neural Nets,\n",
    "                for this code CPU is totally fine).\n",
    "        critic_lr: The learning rate for the critic network (should usually be larger than the actor_lr).\n",
    "        actor_lr: The learning rate for the actor network.\n",
    "        critic_weights: The initial weights of the critic network.\n",
    "        actor_weights: The initial weights of the actor network.\n",
    "        n_envs: The number of environments that run in parallel (on multiple CPUs) to collect experiences.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        n_actions: int,\n",
    "        device: torch.device,\n",
    "        critic_lr: float,\n",
    "        actor_lr: float,\n",
    "        critic_weights: np.ndarray,\n",
    "        actor_weights: np.ndarray,\n",
    "        n_envs: int,\n",
    "    ) -> None:\n",
    "        \"\"\"Initializes the actor and critic networks and their respective optimizers.\"\"\"\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.n_envs = n_envs\n",
    "\n",
    "        critic_layers = [nn.Linear(n_features, 1)] # estimate V(s)\n",
    "        actor_layers = [nn.Linear(n_features, n_actions)] # estimate action logits (will be fed into a softmax later)\n",
    "        \n",
    "        # #initialize the weights of the actor and critic networks\n",
    "        # if critic_weights is not None:\n",
    "        #     self.critic[0].weight.data = torch.Tensor(critic_weights).to(self.device)\n",
    "        # else:\n",
    "        #     #uniformily initialize the weights between -0.001 and 0.001 using nn.init\n",
    "        #     nn.init.uniform_(self.critic.weight, -0.001, 0.001)\n",
    "        # if actor_weights is not None:\n",
    "        #     self.actor[0].weight.data = torch.Tensor(actor_weights).to(self.device)\n",
    "        # else:\n",
    "        #     nn.init.uniform_(self.actor.weight, -0.001, 0.001)\n",
    "\n",
    "        # define actor and critic networks\n",
    "        self.critic = nn.Sequential(*critic_layers).to(self.device)\n",
    "        self.actor = nn.Sequential(*actor_layers).to(self.device)\n",
    "\n",
    "        # define optimizers for actor and critic\n",
    "        self.critic_optim = optim.Adam(self.critic.parameters(), lr=critic_lr)\n",
    "        self.actor_optim = optim.Adam(self.actor.parameters(), lr=actor_lr)\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass of the networks.\n",
    "\n",
    "        Args:\n",
    "            x: A batched vector of states.\n",
    "\n",
    "        Returns:\n",
    "            state_values: A tensor with the state values, with shape [n_envs,].\n",
    "            action_logits_vec: A tensor with the action logits, with shape [n_envs, n_actions].\n",
    "        \"\"\"\n",
    "        x = torch.Tensor(x).to(self.device)\n",
    "        state_values = self.critic(x)  # shape: [n_envs,]\n",
    "        action_logits_vec = self.actor(x)  # shape: [n_envs, n_actions]\n",
    "        return (state_values, action_logits_vec)\n",
    "\n",
    "    def select_action(\n",
    "        self, x: np.ndarray\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Returns a tuple of the chosen actions and the log-probs of those actions.\n",
    "\n",
    "        Args:\n",
    "            x: A batched vector of states.\n",
    "\n",
    "        Returns:\n",
    "            actions: A tensor with the actions, with shape [n_steps_per_update, n_envs].\n",
    "            action_log_probs: A tensor with the log-probs of the actions, with shape [n_steps_per_update, n_envs].\n",
    "            state_values: A tensor with the state values, with shape [n_steps_per_update, n_envs].\n",
    "        \"\"\"\n",
    "        state_values, action_logits = self.forward(x)\n",
    "        action_pd = torch.distributions.Categorical(\n",
    "            logits=action_logits\n",
    "        )  # implicitly uses softmax\n",
    "        actions = action_pd.sample()\n",
    "        action_log_probs = action_pd.log_prob(actions)\n",
    "        entropy = action_pd.entropy()\n",
    "        return (actions, action_log_probs, state_values, entropy)\n",
    "\n",
    "    def get_losses(\n",
    "        self,\n",
    "        rewards: torch.Tensor,\n",
    "        action_log_probs: torch.Tensor,\n",
    "        value_preds: torch.Tensor,\n",
    "        entropy: torch.Tensor,\n",
    "        masks: torch.Tensor,\n",
    "        gamma: float,\n",
    "        lam: float,\n",
    "        ent_coef: float,\n",
    "        device: torch.device,\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Computes the loss of a minibatch (transitions collected in one sampling phase) for actor and critic\n",
    "        using Generalized Advantage Estimation (GAE) to compute the advantages (https://arxiv.org/abs/1506.02438).\n",
    "\n",
    "        Args:\n",
    "            rewards: A tensor with the rewards for each time step in the episode, with shape [n_steps_per_update, n_envs].\n",
    "            action_log_probs: A tensor with the log-probs of the actions taken at each time step in the episode, with shape [n_steps_per_update, n_envs].\n",
    "            value_preds: A tensor with the state value predictions for each time step in the episode, with shape [n_steps_per_update, n_envs].\n",
    "            masks: A tensor with the masks for each time step in the episode, with shape [n_steps_per_update, n_envs].\n",
    "            gamma: The discount factor.\n",
    "            lam: The GAE hyperparameter. (lam=1 corresponds to Monte-Carlo sampling with high variance and no bias,\n",
    "                                          and lam=0 corresponds to normal TD-Learning that has a low variance but is biased\n",
    "                                          because the estimates are generated by a Neural Net).\n",
    "            device: The device to run the computations on (e.g. CPU or GPU).\n",
    "\n",
    "        Returns:\n",
    "            critic_loss: The critic loss for the minibatch.\n",
    "            actor_loss: The actor loss for the minibatch.\n",
    "        \"\"\"\n",
    "        T = len(rewards)\n",
    "        advantages = torch.zeros(T, self.n_envs, device=device)\n",
    "\n",
    "        # compute the advantages using GAE\n",
    "        gae = 0.0\n",
    "        for t in reversed(range(T - 1)):\n",
    "            td_error = (\n",
    "                rewards[t] + gamma * masks[t] * value_preds[t + 1] - value_preds[t]\n",
    "            )\n",
    "            gae = td_error + gamma * lam * masks[t] * gae\n",
    "            advantages[t] = gae\n",
    "\n",
    "        # calculate the loss of the minibatch for actor and critic\n",
    "        critic_loss = advantages.pow(2).mean()\n",
    "\n",
    "        # give a bonus for higher entropy to encourage exploration\n",
    "        actor_loss = (\n",
    "            -(advantages.detach() * action_log_probs).mean() - ent_coef * entropy.mean()\n",
    "        )\n",
    "        return (critic_loss, actor_loss)\n",
    "\n",
    "    def update_parameters(\n",
    "        self, critic_loss: torch.Tensor, actor_loss: torch.Tensor\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Updates the parameters of the actor and critic networks.\n",
    "\n",
    "        Args:\n",
    "            critic_loss: The critic loss.\n",
    "            actor_loss: The actor loss.\n",
    "        \"\"\"\n",
    "        self.critic_optim.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optim.step()\n",
    "\n",
    "        self.actor_optim.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optim.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define imitation learning agent model \n",
    "#TODO look up how to do this"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline RL on CartPole v1 (with linear function approximation or single layer perceptron)\n",
    "\n",
    "Gathering Expert Data\n",
    "* Train the expert models before gathering\n",
    "* Gather 500 behavior episodes in the task using last agent (Actor-Critic)\n",
    "* Gather 500 episodes using uniformly random policy\n",
    "\n",
    "Offline Training,\n",
    "1. Simple imitation learning, use logistic regression to imitate the action observed in each state\n",
    "2. Fitted Q-learning, using Q-learning targets, only with the batch of data given, K number of iterations on the episodes collected\n",
    "    1. initialize Q-function randomly between -0.001 and 0.001\n",
    "    2. Use two different learning rate settings 1/8 and 1/16\n",
    "3. train with 100, 250, and 500 episodes data (3 data methods x 3 data size = 9 experiments)\n",
    "    1. Use episodes with expert (Actor-Critic) to train the model\n",
    "    2. Use episodes with uniform random to train the model\n",
    "    3. Select at random, half episode from random, half from expert\n",
    "4. Run greedy policy on the trained model for 100 episodes, and plot the return in a bar chart showing the average and s.d of the return for each of the 9 experiments (6 bars for each data set size) draw two horizontal lines at the average return of the offline RL methods (the same number of episode data). 3 graphs in total.\n",
    "\n",
    "Write a small report that describes your experiment, including how you decided to stop the training,\n",
    "the results, and the conclusions you draw from this experimentation. Comment on whether the\n",
    "algorithms are matching and/or exceeding the performance of the policies used to generate the\n",
    "data. Comment also on the impact of the data set size and data quality on the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters to gather expert data \n",
    "experiment_count = 1\n",
    "episode_count = 2000 #number of episodes to gather expert data\n",
    "\n",
    "\n",
    "# set hyperparameters for linear function approximator\n",
    "bins = 10 #number of bins for discretization as features for linear function approximator\n",
    "num_features = bins**4 #number of features for linear function approximator\n",
    "num_actions = 2 #number of actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define initial weights for linear function approximator\n",
    "critic_weights = np.random.uniform(-0.001, 0.001, num_features)\n",
    "#actor_weights = np.random.uniform(-0.001, 0.001, (num_features, num_actions)) #different action weights\n",
    "actor_weights = np.stack((critic_weights, critic_weights), axis=1) #same action weights\n",
    "actor_weights_ac = np.random.uniform(-0.001, 0.001, (num_actions, num_features))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2C data collection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train expert agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment hyperparams\n",
    "n_envs = 1\n",
    "n_steps_per_update = 500  # number of steps before updating the network, max number of steps\n",
    "randomize_domain = False\n",
    "\n",
    "# agent hyperparams\n",
    "lam = 0.95  # hyperparameter for GAE, TD(lambda) lam = 1 is equivalent to MC, lam = 0 is equivalent to TD(0)\n",
    "ent_coef = 0.01  # coefficient for the entropy bonus (to encourage exploration)\n",
    "alpha = 1/16 #learning rates actor \n",
    "beta = 1/4 #learning rates critic (betas are 4x larger than alphas)\n",
    "device = \"cpu\"\n",
    "# Note: the actor has a slower learning rate so that the value targets become\n",
    "# more stationary and are theirfore easier to estimate for the critic\n",
    "\n",
    "#initialize arrays to store the average rewards for each episode, each experiment, each alphas for Actor-Critic\n",
    "critic_losses_ac_nn = np.zeros((experiment_count, episode_count))\n",
    "actor_losses_ac_nn = np.zeros((experiment_count, episode_count))\n",
    "entropies_ac_nn = np.zeros((experiment_count, episode_count))\n",
    "rewards_ac_nn = np.zeros((experiment_count, episode_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 0 alpha: 0.0625 beta: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]c:\\Users\\ccarc\\Anaconda3\\envs\\torch_gpu\\lib\\site-packages\\ipykernel_launcher.py:88: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "100%|██████████| 2000/2000 [51:49<00:00,  1.55s/it] \n",
      "c:\\Users\\ccarc\\Anaconda3\\envs\\torch_gpu\\lib\\site-packages\\ipykernel_launcher.py:123: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "#training the expert agent\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "#use encoder to discretize the state space\n",
    "oh = OneHotFA(env, bins)\n",
    "env.close()\n",
    "\n",
    "#define an array to store the state, action, next_state, reward for each episode for each experiment\n",
    "expert_data_ac_temp = []\n",
    "#gather data and loop over all experiments for A2C agent\n",
    "for exp in range(experiment_count):\n",
    "    print(\"Experiment: \" + str(exp) + \" alpha: \" + str(alpha) + \" beta: \" + str(beta))\n",
    "    \n",
    "    #initialize the A2C agent\n",
    "    agent = A2C(num_features, num_actions, device = device, critic_lr=beta, actor_lr=alpha, critic_weights=critic_weights, actor_weights=actor_weights_ac, n_envs=n_envs)\n",
    "    \n",
    "    agent.critic[0].weight.data = torch.Tensor(critic_weights).to(device)\n",
    "    agent.actor[0].weight.data = torch.Tensor(actor_weights_ac).to(device)\n",
    "    \n",
    "    #envs = gym.vector.make('CartPole-v1', num_envs=n_envs, render_mode='rgb_array', max_episode_steps=600)\n",
    "    envs = gym.vector.make('CartPole-v1', num_envs=n_envs)\n",
    "    # create a wrapper environment to save episode returns and episode lengths\n",
    "    envs_wrapper = gym.wrappers.RecordEpisodeStatistics(envs, deque_size=n_envs * episode_count)\n",
    "    \n",
    "\n",
    "    critic_losses = []\n",
    "    actor_losses = []\n",
    "    entropies = []\n",
    "    episode_data = []\n",
    "    rewards_each_ep = np.zeros(episode_count)\n",
    "    \n",
    "    # use tqdm to get a progress bar for training\n",
    "    for ep in tqdm(range(episode_count)):\n",
    "    \n",
    "        # reset lists that collect experiences of an episode (sample phase)\n",
    "        ep_value_preds = torch.zeros(n_steps_per_update, n_envs, device=device)\n",
    "        ep_rewards = torch.zeros(n_steps_per_update, n_envs, device=device)\n",
    "        ep_action_log_probs = torch.zeros(n_steps_per_update, n_envs, device=device)\n",
    "        masks = torch.zeros(n_steps_per_update, n_envs, device=device)\n",
    "\n",
    "        #initialize the discrete state space\n",
    "        state_discrete = np.zeros((n_envs, num_features))\n",
    "        next_state_discrete = np.zeros((n_envs, num_features))\n",
    "\n",
    "        # at the start of training reset all envs to get an initial state\n",
    "        #if ep == 0:\n",
    "        states, info = envs_wrapper.reset(seed=seed)\n",
    "        #discretize the state space for each n_envs\n",
    "        for i in range(n_envs):\n",
    "            state_discrete[i], _ = oh.discretize_state(states[i])\n",
    "        truncated = False\n",
    "        terminated = False\n",
    "        step = 0\n",
    "        episode_memory = []\n",
    "        # play n steps in our parallel environments to collect data\n",
    "        #for step in range(n_steps_per_update):\n",
    "        while not (terminated or truncated):\n",
    "            # select an action A_{t} using S_{t} as input for the agent\n",
    "\n",
    "            actions, action_log_probs, state_value_preds, entropy = agent.select_action(\n",
    "                torch.from_numpy(state_discrete).float().unsqueeze(0).to(device=device)\n",
    "            )\n",
    "            # perform the action A_{t} in the environment to get S_{t+1} and R_{t+1}\n",
    "            states, rewards, terminated, truncated, infos = envs_wrapper.step(\n",
    "                actions.numpy()[0]\n",
    "            )\n",
    "            #store the total discounted rewards for each episode\n",
    "            rewards_each_ep[ep] += rewards * (gamma ** step)\n",
    "    \n",
    "            #discretize the state space for each n_envs\n",
    "            for i in range(n_envs):\n",
    "                next_state_discrete[i], _ = oh.discretize_state(states[i])\n",
    "            \n",
    "\n",
    "            episode_memory.append((state_discrete.squeeze(), np.array(actions.squeeze().item()), next_state_discrete.squeeze(), rewards.squeeze()))\n",
    "\n",
    "            state_discrete = next_state_discrete\n",
    "\n",
    "            ep_value_preds[step] = torch.squeeze(state_value_preds)\n",
    "            ep_rewards[step] = torch.tensor(rewards, device=device)\n",
    "            ep_action_log_probs[step] = action_log_probs\n",
    "    \n",
    "            # add a mask (for the return calculation later);\n",
    "            # for each env the mask is 1 if the episode is ongoing and 0 if it is terminated (not by truncation!)\n",
    "            masks[step] = torch.tensor([not term for term in terminated])\n",
    "            step += 1\n",
    "\n",
    "\n",
    "        episode_data.append(np.array(episode_memory))\n",
    "\n",
    "        \n",
    "        # calculate the losses for actor and critic\n",
    "        critic_loss, actor_loss = agent.get_losses(\n",
    "            ep_rewards,\n",
    "            ep_action_log_probs,\n",
    "            ep_value_preds,\n",
    "            entropy,\n",
    "            masks,\n",
    "            gamma,\n",
    "            lam,\n",
    "            ent_coef,\n",
    "            device,\n",
    "        )\n",
    "    \n",
    "        # update the actor and critic networks\n",
    "        agent.update_parameters(critic_loss, actor_loss)\n",
    "    \n",
    "        # log the losses and entropy\n",
    "        critic_losses.append(critic_loss.detach().cpu().numpy())\n",
    "        actor_losses.append(actor_loss.detach().cpu().numpy())\n",
    "        entropies.append(entropy.detach().mean().cpu().numpy())\n",
    "\n",
    "    #save critic losses for each experiment\n",
    "    critic_losses_ac_nn[exp, :] = critic_losses\n",
    "    #save actor losses for each experiment\n",
    "    actor_losses_ac_nn[exp, :] = actor_losses\n",
    "    #save entropy for each experiment\n",
    "    entropies_ac_nn[exp, :] = entropies\n",
    "\n",
    "    #save the rewards for each episode\n",
    "    rewards_ac_nn[exp, :] = rewards_each_ep\n",
    "\n",
    "    #save the episode data\n",
    "    expert_data_ac_temp.append(np.array(episode_data))\n",
    "\n",
    "    #close the environment\n",
    "    envs_wrapper.close()\n",
    "\n",
    "expert_data_ac_temp = np.array(expert_data_ac_temp).squeeze() #with one experiment use squeeze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot and label the curve with mean over all experiments for each episode for actor and critic nn\n",
    "#all in one plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(np.mean(rewards_ac_nn[:,:], axis=0), label='A2C returns')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average Return per experiment')\n",
    "plt.title('A2C returns training 2000 episodes')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the shape of the expert data for actor critic\n",
    "print(expert_data_ac_temp.shape) # number of episodes in first experiment\n",
    "print(expert_data_ac_temp.squeeze().shape) # number of episodes in first experiment\n",
    "print(expert_data_ac_temp[0].shape) # number of steps in first episode\n",
    "print(expert_data_ac_temp[0][0].shape) # shape of first step S_t, A_t, S_t+1, R_t\n",
    "print(expert_data_ac_temp[0][0]) # first step values S_t, A_t, S_t+1, R_t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering 500 episodes of expert data A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters to gather expert data \n",
    "experiment_count = 1\n",
    "episode_count = 500 #number of episodes to gather expert data\n",
    "\n",
    "# set hyperparameters for training\n",
    "episode_cs = [100, 250, 500] #number of episode sizes \n",
    "alphas = [1/8, 1/16] #learning rates \n",
    "gamma = 0.99 #discount factor\n",
    "\n",
    "\n",
    "# set hyperparameters for linear function approximator\n",
    "bins = 10 #number of bins for discretization as features for linear function approximator\n",
    "num_features = bins**4 #number of features for linear function approximator\n",
    "num_actions = 2 #number of actions\n",
    "\n",
    "#initialize arrays to store the average rewards for each episode, each experiment, each alphas for Actor-Critic\n",
    "critic_losses_ac_nn = np.zeros((experiment_count, episode_count))\n",
    "actor_losses_ac_nn = np.zeros((experiment_count, episode_count))\n",
    "entropies_ac_nn = np.zeros((experiment_count, episode_count))\n",
    "rewards_ac_nn = np.zeros((experiment_count, episode_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0019,  0.0096,  0.0090,  ..., -0.0025,  0.0025,  0.0015]])\n",
      "tensor([[-1.8484e-04,  7.3926e-03, -2.0118e-03,  ..., -4.5437e-03,\n",
      "         -5.8904e-03,  5.8074e-04],\n",
      "        [-6.1527e-03,  4.1943e-05, -2.7259e-03,  ..., -3.8570e-03,\n",
      "          9.1785e-03, -4.2362e-03]])\n",
      "tensor([-0.0003,  0.0009,  0.0005,  ...,  0.0009, -0.0002, -0.0006])\n",
      "tensor([[-0.0003, -0.0003, -0.0006,  ..., -0.0004, -0.0001, -0.0007],\n",
      "        [ 0.0005, -0.0006, -0.0003,  ..., -0.0010, -0.0002, -0.0005]])\n"
     ]
    }
   ],
   "source": [
    "#save A2C agent model weights using torch save\n",
    "# torch.save(agent.critic[0].weight.data, 'critic_weights_ac_nn.pt')\n",
    "# torch.save(agent.actor[0].weight.data, 'actor_weights_ac_nn.pt')\n",
    "\n",
    "\n",
    "#load agent model using torch load\n",
    "agent = A2C(num_features, num_actions, device = device, critic_lr=beta, actor_lr=alpha, critic_weights=critic_weights, actor_weights=actor_weights_ac, n_envs=n_envs)\n",
    "\n",
    "#print agent weights\n",
    "print(agent.critic[0].weight.data)\n",
    "print(agent.actor[0].weight.data)\n",
    "\n",
    "#load agent model weights using torch load\n",
    "agent.critic[0].weight.data = torch.load('critic_weights_ac_nn.pt')\n",
    "agent.actor[0].weight.data = torch.load('actor_weights_ac_nn.pt')\n",
    "\n",
    "#print agent weights\n",
    "print(agent.critic[0].weight.data)\n",
    "print(agent.actor[0].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 0 alpha: 0.0625 beta: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]c:\\Users\\ccarc\\Anaconda3\\envs\\torch_gpu\\lib\\site-packages\\ipykernel_launcher.py:76: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "100%|██████████| 500/500 [10:00<00:00,  1.20s/it]\n",
      "c:\\Users\\ccarc\\Anaconda3\\envs\\torch_gpu\\lib\\site-packages\\ipykernel_launcher.py:110: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "#define an array to store the state, action, next_state, reward for each episode for each experiment\n",
    "expert_data_ac = []\n",
    "#gather data and loop over all experiments for A2C agent\n",
    "for exp in range(experiment_count):\n",
    "    print(\"Experiment: \" + str(exp) + \" alpha: \" + str(alpha) + \" beta: \" + str(beta))\n",
    "    \n",
    "    #using the previous trained A2C agent\n",
    "    \n",
    "    #envs = gym.vector.make('CartPole-v1', num_envs=n_envs, render_mode='rgb_array', max_episode_steps=600)\n",
    "    envs = gym.vector.make('CartPole-v1', num_envs=n_envs)\n",
    "    #create a wrapper environment to save episode returns and episode lengths\n",
    "    envs_wrapper = gym.wrappers.RecordEpisodeStatistics(envs, deque_size=n_envs * episode_count)\n",
    "    \n",
    "    critic_losses = []\n",
    "    actor_losses = []\n",
    "    entropies = []\n",
    "    episode_data = []\n",
    "    rewards_each_ep = np.zeros(episode_count)\n",
    "    \n",
    "    # use tqdm to get a progress bar for training\n",
    "    for ep in tqdm(range(episode_count)):\n",
    "    \n",
    "        # reset lists that collect experiences of an episode (sample phase)\n",
    "        ep_value_preds = torch.zeros(n_steps_per_update, n_envs, device=device)\n",
    "        ep_rewards = torch.zeros(n_steps_per_update, n_envs, device=device)\n",
    "        ep_action_log_probs = torch.zeros(n_steps_per_update, n_envs, device=device)\n",
    "        masks = torch.zeros(n_steps_per_update, n_envs, device=device)\n",
    "\n",
    "        #initialize the discrete state space\n",
    "        state_discrete = np.zeros((n_envs, num_features))\n",
    "        next_state_discrete = np.zeros((n_envs, num_features))\n",
    "\n",
    "        # at the start of training reset all envs to get an initial state\n",
    "        #if ep == 0:\n",
    "        states, info = envs_wrapper.reset(seed=seed)\n",
    "        #discretize the state space for each n_envs\n",
    "        for i in range(n_envs):\n",
    "            state_discrete[i], _ = oh.discretize_state(states[i])\n",
    "        truncated = False\n",
    "        terminated = False\n",
    "        step = 0\n",
    "        episode_memory = []\n",
    "        # play n steps in our parallel environments to collect data\n",
    "        #for step in range(n_steps_per_update):\n",
    "        while not (terminated or truncated):\n",
    "            # select an action A_{t} using S_{t} as input for the agent\n",
    "\n",
    "            actions, action_log_probs, state_value_preds, entropy = agent.select_action(\n",
    "                torch.from_numpy(state_discrete).float().unsqueeze(0).to(device=device)\n",
    "            )\n",
    "            # perform the action A_{t} in the environment to get S_{t+1} and R_{t+1}\n",
    "            states, rewards, terminated, truncated, infos = envs_wrapper.step(\n",
    "                actions.numpy()[0]\n",
    "            )\n",
    "            #store the total discounted rewards for each episode\n",
    "            rewards_each_ep[ep] += rewards * (gamma ** step)\n",
    "    \n",
    "            #discretize the state space for each n_envs\n",
    "            for i in range(n_envs):\n",
    "                next_state_discrete[i], _ = oh.discretize_state(states[i])\n",
    "            \n",
    "\n",
    "            episode_memory.append((state_discrete.squeeze(), np.array(actions.squeeze().item()), next_state_discrete.squeeze(), rewards.squeeze()))\n",
    "\n",
    "            state_discrete = next_state_discrete\n",
    "\n",
    "            ep_value_preds[step] = torch.squeeze(state_value_preds)\n",
    "            ep_rewards[step] = torch.tensor(rewards, device=device)\n",
    "            ep_action_log_probs[step] = action_log_probs\n",
    "    \n",
    "            # add a mask (for the return calculation later);\n",
    "            # for each env the mask is 1 if the episode is ongoing and 0 if it is terminated (not by truncation!)\n",
    "            masks[step] = torch.tensor([not term for term in terminated])\n",
    "            step += 1\n",
    "\n",
    "        episode_data.append(np.array(episode_memory))\n",
    "        \n",
    "        # calculate the losses for actor and critic\n",
    "        critic_loss, actor_loss = agent.get_losses(\n",
    "            ep_rewards,\n",
    "            ep_action_log_probs,\n",
    "            ep_value_preds,\n",
    "            entropy,\n",
    "            masks,\n",
    "            gamma,\n",
    "            lam,\n",
    "            ent_coef,\n",
    "            device,\n",
    "        )\n",
    "    \n",
    "        # update the actor and critic networks\n",
    "        agent.update_parameters(critic_loss, actor_loss)\n",
    "    \n",
    "        # log the losses and entropy\n",
    "        critic_losses.append(critic_loss.detach().cpu().numpy())\n",
    "        actor_losses.append(actor_loss.detach().cpu().numpy())\n",
    "        entropies.append(entropy.detach().mean().cpu().numpy())\n",
    "\n",
    "    #save critic losses for each experiment\n",
    "    critic_losses_ac_nn[exp, :] = critic_losses\n",
    "    #save actor losses for each experiment\n",
    "    actor_losses_ac_nn[exp, :] = actor_losses\n",
    "    #save entropy for each experiment\n",
    "    entropies_ac_nn[exp, :] = entropies\n",
    "\n",
    "    #save the rewards for each episode\n",
    "    rewards_ac_nn[exp, :] = rewards_each_ep\n",
    "\n",
    "    #save the episode data\n",
    "    expert_data_ac.append(np.array(episode_data))\n",
    "\n",
    "    #close the environment\n",
    "    envs_wrapper.close()\n",
    "\n",
    "expert_data_ac = np.array(expert_data_ac).squeeze() #with one experiment use squeeze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot and label the curve with mean over all experiments for each episode for actor and critic nn\n",
    "#all in one plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(np.mean(rewards_ac_nn[:,:], axis=0), label='A2C returns')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average Return per experiment')\n",
    "plt.title('A2C returns gathered 500 episodes')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(500,)\n",
      "(500, 4)\n",
      "(4,)\n",
      "[array([0., 0., 0., ..., 0., 0., 0.]) array(1)\n",
      " array([0., 0., 0., ..., 0., 0., 0.]) array(1.)]\n"
     ]
    }
   ],
   "source": [
    "#print the shape of the expert data for actor critic\n",
    "#shape shows every episode ended up with optimal reward eg. 500 steps\n",
    "print(expert_data_ac.shape) # number of episodes in first experiment\n",
    "print(expert_data_ac.squeeze().shape) # number of episodes in first experiment\n",
    "print(expert_data_ac[0].shape) # number of steps in first episode\n",
    "print(expert_data_ac[0][0].shape) # shape of first step S_t, A_t, S_t+1, R_t\n",
    "print(expert_data_ac[0][0]) # first step values S_t, A_t, S_t+1, R_t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather 500 episodes using Uniform random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform random policy Experiment: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]c:\\Users\\ccarc\\Anaconda3\\envs\\torch_gpu\\lib\\site-packages\\ipykernel_launcher.py:66: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "100%|██████████| 500/500 [00:29<00:00, 16.94it/s]\n",
      "c:\\Users\\ccarc\\Anaconda3\\envs\\torch_gpu\\lib\\site-packages\\ipykernel_launcher.py:72: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "expert_data_uf = []\n",
    "\n",
    "#gather data and loop over all experiments for uniformly random policy\n",
    "rewards_uf = np.zeros((experiment_count, episode_count))\n",
    "\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "#use encoder to discretize the state space\n",
    "ofa = OneHotFA(env, bins)\n",
    "env.close()\n",
    "\n",
    "for exp in range(experiment_count):\n",
    "    print(\"Uniform random policy Experiment: \" + str(exp))\n",
    "    #initialize the environment\n",
    "    env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "\n",
    "    # #initialize the linear function approximator\n",
    "    # ofa = OneHotFA(env, bins, actor_weights, critic_weights)\n",
    "    # #ofa.print_params()\n",
    "    \n",
    "    #run q-learning\n",
    "    # Initialize a table to count the rewards for each episode\n",
    "    rewards_each_ep = np.zeros(episode_count)\n",
    "    episode_data = []\n",
    "\n",
    "    # Initialize a table to count the number of steps for each episode\n",
    "    steps = np.zeros(episode_count)\n",
    "\n",
    "    # Loop over episodes\n",
    "    for ep in tqdm(range(episode_count)):\n",
    "        # initialize state and action for current episode\n",
    "        state, info = env.reset(seed=seed) \n",
    "        state_discrete, state_index = ofa.discretize_state(state)\n",
    "        truncated = False\n",
    "        terminated = False\n",
    "        \n",
    "        episode_memory = []\n",
    "        \n",
    "        # Loop over time steps within the episode\n",
    "        while not (terminated or truncated):\n",
    "\n",
    "            # Choose the next action using uniform random policy\n",
    "            action = uniform_random(num_actions)\n",
    "            # Take the chosen action and observe the next state and reward\n",
    "            next_state, reward, terminated, truncated, info = env.step(action)\n",
    "            # Discretize the next state\n",
    "            next_state_discrete, next_state_index = ofa.discretize_state(next_state)\n",
    "\n",
    "            episode_memory.append((state_discrete, np.asarray(action), next_state_discrete, np.asarray(reward)))\n",
    "\n",
    "            # if steps[ep] == 0 or steps[ep] == 1:\n",
    "            #     print(episode_memory)\n",
    "            #     #print shape\n",
    "            #     print(\"episode_memory: \", np.array(episode_memory).shape)\n",
    "                \n",
    "            # Update the state\n",
    "            state_discrete = next_state_discrete\n",
    "\n",
    "            # store the total reward for each episode\n",
    "            rewards_each_ep[ep] += reward * (gamma ** step)\n",
    "\n",
    "            # store the number of steps for each episode\n",
    "            steps[ep] += 1\n",
    "\n",
    "            env.render()\n",
    "\n",
    "        episode_data.append(np.array(episode_memory))\n",
    "\n",
    "    #save the rewards for each episode\n",
    "    rewards_uf[exp, :] = rewards_each_ep\n",
    "\n",
    "    #save the episode data\n",
    "    expert_data_uf.append(np.array(episode_data))\n",
    "\n",
    "    #close the environment\n",
    "    env.close()\n",
    "\n",
    "expert_data_uf = np.array(expert_data_uf).squeeze() #with one experiment use squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAFNCAYAAABIc7ibAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAB6KklEQVR4nO3dd3ib5dX48e+RvOUZO85wEid2EkL2ZAYIUFaZXaxSyksphS46aEv7a6HQ8bbvS8dbSkuhLaUUChRKS9kjhJ1NdgjZtuMkjveQbVnS/fvjkRzF8Xi0LNk5n+vKFVvzlh5ZOjr3uc8txhiUUkoppdTgciR6AEoppZRSxyINwpRSSimlEkCDMKWUUkqpBNAgTCmllFIqATQIU0oppZRKAA3ClFJKKaUSQIMwpUKIyH0i8oOQ328WkYMi0ioihYkcWzyIiBGRyYkex7FERJaJyA0Juu/rROTtRNx3rIjIp0Xk5Rjf5sTA30JKLG9XqYFoEKaGld6CChH5oYj8zc71jTE3GWN+FLheKvBL4FxjTLYxpi72I1a9EZG/iMiPEz2OaIXz2ksGgb+ftsCXjlYR+WOP878uIgdEpElE/iwi6SHnjRCRpwPX3ysiV8djjMaYR4wx58bjtpUabBqEKdW3UUAGsDncK4olpn9fw+Vbejyem17uY1g8V/2J4/M4J/ClI9sY052xE5HzgNuAs4GJQBlwZ8j17gU8WH83nwZ+LyIz4jA+pYYNDcLUMUVElohIlYh8U0RqRGS/iPxXyPl/EZEfi8hUYFvg5EYRWRo4/xQRWRXIBKwSkVNCrrtMRH4iIu8AbqAskFn4oohsF5EWEfmRiJSLyHsi0iwiT4hIWh9jvU5E3hGRX4lIPfDDwHWXikidiNSKyCMikh9ynT0icquIbAiM8XERyQg5/1uBx1wtItf3uL88EfmriBwKZDK+H/yQ7zGWRhHZFXgurhORysBz+dl+nvfenptpIvKKiNSLyDYRuTxw2RuxPsS/HcjG/Cdw+hFZztBsWchx/Y6IHAAeDGShngg8phYR2SwiC0Ou/x0R2Rc4b5uInN3H2AtF5D+B47Uq8Pp4O+T8/ws8B80iskZETgucfj7wPeCKwONYH3KzpYHns0VEXhaRopDbO0lE3g08z+tFZEkkz2PI2J8JjG0lUN7XMbLhs8CfjDGbjTENwI+A6wL34wI+AfzAGNNqjHkbeAb4TF83JiLXi8hWEWkQkZdEpDTkPCMiXw28zmpF5H97vBbfDvwsgddkTeD1vkFEZgbO6+/17BSRuwO3vQu4sMfY8kTkT4G/lX2BY+4MnDdZRN4I3F+tiDwexXOqjnXGGP2n/4bNP8AAk3uc9kPgb4GflwBe4C4gFfgo1odZQeD8vwA/Dvw8MXB7KYHfRwANWB8sKcBVgd8LA+cvAyqAGYHzUwPXfwbIDZzeCbyGlUXIA7YAn+3jsVwXGOtXAreXCUwGzgHSgZHAm8CvQ66zB1gJjA2MdytwU+C884GDwEzABTwa+nwBfwX+DeQEHvuHwOd6jOW/ACfw48BjvTcwlnOBFiC7j8fS87nJAyoDt5cCzAdqgRk9j0Nfx7bHsQoe158HxpMZOO4dgWPsBP4bWB64/HGB+x8bcqzL+xj7Y4F/WcD0wPXeDjn/GqAw8Di+CRwAMnq+9no8FzuBqYFxLgN+FjivBKgLjNkRONZ1wMgIn8fHgCcCx3smsC907H38/VQHHsM/gYkh560Hrgj5vShw+UJgHtDe47ZuBf7Tx/1cBuwAjg+M+/vAuz3G8TrWa3gC1mvxhpDX4tuBn88D1gD5gARub4yN1/NNwAfA+MB9vM6Rf+v/Av4QeN6Ksf6mvhA47+/A/wscnwxgcaLf9/Tf0P2nmTB1LOoC7jLGdBljngdasT6UB3IhsN0Y87AxxmuM+TvWG/nFIZf5i7EyBV5jTFfgtJ8bY5qNMZuBTcDLxphdxpgm4AWsD7C+VBtj7gncXrsxZocx5hVjTKcx5hBWzdoZPa7zG2NMtTGmHvgPMDdw+uXAg8aYTcaYNqwAAbAyA8AVwHeNMS3GmD3ALzgyk7HbGPOgMcYHPI71AXZXYCwvY01F9Vfk3/3cYAWEewK35zXGrAWeAj7Zz/UH4gfuCIynPXDa28aY5wNjfhiYEzjdhxWsTReRVGPMHmPMzp43GHhePhG4XbcxZgvwUOhljDF/M8bUBR7HLwK3O9Dr6UFjzIeBcT7B4WN0DfB8YMx+Y8wrwGqsoCzI1vMYMvbbjTFtxphNPcfeizOwApZpWMHYs3J4ajcbaAq5bPDnnF7OC56f08f9fAH4b2PM1sDj+CkwNzQbhvV3U2+MqQB+jfWlp6euwH1MAyRwe/ttvJ4vx/ryUhn4O/nv4A2KyCjgAuBrgeetBvgVcGXIfZZiBfAdxsr6KRURDcLUcOPDykCFSsV64wyqC7zxB7mxPkQGMhbY2+O0vVjZi6DKXq53MOTn9l5+7+++j7g9ESkWkccCUyTNwN+wMhKhDoT8HPrYxva4vdDHUgSk9Tit52PrOW6MMZE+llLgxMCUW6OINGJNQY7u5/oDOWSM6ehxWs/nIkNEUowxO4CvYQWiNYHndGwvtzkSK1MTOvaex+SbgWm1psDjyOPoY9JTX8eoFPhUj+dlMTCmj/vv73nsbew9X79HMMa8aYzxGGMagVuASVjZJbC+rOSGXDz4c0sv5wXPb+njrkqB/wsZcz1WJquvv6W9WK/fnuNdCvwWKyN7UETuF5FcBn499/e3UIr1nrE/ZHx/wMqIAXw7MNaVgSnuI6b1lQqHBmFquKnA+iYfahIDfPjYVI31Bh1qAtYUT5CJwf2E6nl7/x04bbYxJhcrcyI2b2s/VvYqaELIz7Uc/oYfen7oY4tW6GOpBN4wxuSH/Ms2xtzcy2WD3FhTgkE9A7awnntjzKPGmMVYj9lgTWX2dAhrmnNcyGndz2Gg/us7WJmVAmNMPlYGKHhMwn09VAIP93heXMaYn4UOvcfl+3oeg2Pv65jbYUIey2YOZxIJ/HzQWKuGPwRSRGRKj/P7WtRSiTW9FzruTGPMuyGX6Tnu6l4HaMxvjDELsKZopwLfYuDXc39/C5VYZQNFIWPLNcbMCNzfAWPM540xY7Eyer8TbfOiIqRBmBpuHge+LyLjRMQhIh/Bmi58Mga3/TwwVUSuFpEUEbkCq0bo2Rjctl05WFmHRhEpwfrAsesJ4DoRmS4iWcAdwTMC03VPAD8RkZzAtNA3sDJt8fAs1nP5GRFJDfxbJCLBrMtBrLq5UOuAqwNF1edz9DSsbSJynIicJVaLhQ6sLJ6v5+UCz8s/sRZFZInINODakIvkYAU6h7CCkNs5MiN0EJgo9lcx/g24WETOCzzODLEWHYzr4/J9Po+9jH06VnF9X8/JDBGZG7jfbKzpu31YdYVg1Vh9LvD6KcCq4/pL4HlqC9zXXSLiEpFTgUuxpoB7cx/wXQmsngwUwn+qx2W+JSIFIjIeKyt3VAF84LGeKFY7mTasY+mz8Xp+Avhq4H2iAGvVJ4HHsh94GfiFiOQG3kfKReSMwH1+KuR4NGAFqke9dpSyQ4MwNdzcBbwLvI31Bvk/wKcD9TBRCXzjvwir+LoOa1riImNMbbS3HYY7sYqvm4DnsD74bDHGvIBVW7MUqyh6aY+LfAXrg2wX1vP3KPDnqEfc+1hasIr5r+RwIXiwqB7gT1j1Wo0i8q/AabdgBdSNWFNu/yJy6cDPsDImB7Cmmr7Xx2W/jDXFeAArqPg7VqYE4CWsur4PsbKtHRw5zfWPwP91IrJ2oEEZYyqxgpfvYQV2lViBdq/v1Taexy9jTXUewAqYHuzn7kdhBTrNWK+BiViv767Afb2I9ff0euCx7iUkkAe+iLXQoAbrObo5UAfZ27ifDozzscC0+iasOqxQ/8Yqul+H9Vr/Uy83lQs8gPW3vhfr7/LuwHn9vZ4fwDp264G1HP13dC3WdOaWwG0/yeEp4UXAChFpxVp0c4sxZndvj1OpgYgxsZ49UUqp4UtEfg6MNsb0mVVS0RERA0wJ1O4pNWxpJkwppfohVh+u2WI5Afgc8HSix6WUGvqGfVdppZSKUg7W9NpYrKm2X2BNlSmlVFR0OlIppZRSKgF0OlIppZRSKgE0CFNKKaWUSoAhVxNWVFRkJk6cGPf7aWtrw+Vyxf1+VPj02CQ3PT7JS49NctPjk7yiOTZr1qypNcaM7O28IReETZw4kdWrV8f9fpYtW8aSJUvifj8qfHpskpsen+Slxya56fFJXtEcGxHpc8cWnY5USimllEoADcKUUkoppRJAgzCllFJKqQQYcjVhvenq6qKqqoqOjo6Y3WZeXh5bt24d+IJq0CX62GRkZDBu3DhSU1MTNgallFJD37AIwqqqqsjJyWHixImISExus6WlhZycnJjcloqtRB4bYwx1dXVUVVUxadKkhIxBKaXU8DAspiM7OjooLCyMWQCmVF9EhMLCwphmXZVSSh2bhkUQBmgApgaNvtaUUkrFwrAJwhJpz549zJw584jTfvjDH3L33Xf3e73Vq1fz1a9+FYDOzk4+8pGPMHfuXB5//PG4jTUeJk6cSG1tbULue926dTz//PMJuW+llFIqGsOiJmyoWrhwIQsXLgTg/fffp6uri3Xr1tm+vs/nw+l0Rnz/xhiMMTgcyR2Le71eUlJ6f6muW7eO1atX89GPftT27Q2Vx62UUmp400+hQbBkyRK+853vcMIJJzB16lTeeustwOrAe9FFF1FTU8M111zDunXrmDt3Ljt37uS1115j3rx5zJo1i+uvv57Ozk7AyjrdddddLF68mH/84x9MnDiR733ve5x88sksXLiQtWvXct5551FeXs5999131Fj27NnD8ccfzxe/+EXmz59PZWUlN998MwsXLmTGjBnccccd3ZedOHEid9xxB/Pnz2fWrFl88MEHANTV1XHuuecyb948vvCFL2CM6b7OL3/5S2bOnMnMmTP59a9/3X2f06ZN44YbbmDmzJl8+tOf5tVXX+XUU09lypQprFy58qhx/uUvf+FTn/oUF198Meeeey5tbW1cf/31LFq0iMWLF/Pvf/8bj8fD7bffzuOPP96dQeyZgZw5cyZ79uw56nG/9dZbHH/88Xz+859nxowZnHvuubS3twPwm9/8hunTpzN79myuvPLKKI++Umq42Xmolcp6d6KHoYYBDcIGidfrZeXKlfz617/mzjvvPOK84uJi/vjHP3Laaaexbt06SkpKuO6663j88cfZuHEjXq+X3//+992Xz8jI4O233+4OEMaPH897773HaaedxnXXXceTTz7J8uXLuf3223sdy7Zt27j22mt5//33KS0t5Sc/+QmrV69mw4YNvPHGG2zYsKH7skVFRaxdu5abb765O7i58847Wbx4Me+//z6XXHIJFRUVAKxZs4YHH3yQFStWsHz5ch544AHef/99AHbs2MEtt9zChg0b+OCDD3j00Ud5++23ufvuu/npT3/a6zjfe+89HnroIZYuXcpPfvITzjrrLFatWsWzzz7Lt771Lbq6urjrrru44oorWLduHVdccUW/x6Dn496+fTtf+tKX2Lx5M/n5+Tz11FMA/OxnP+P9999nw4YNvQaySqlj27ef3MBdz25J9DDUMDDspiPv/M9mtlQ3R307oVN908fmcsfFM/q8bF+F2qGnf/zjHwdgwYIF7Nmzp9/73rZtG5MmTWLq1KkAfPazn+Xee+/la1/7GsBRwcYll1wCwKxZs2htbSUnJ4ecnBwyMjJobGwkPz//iMuXlpZy0kkndf/+xBNPcP/99+P1etm/fz9btmxh9uzZR437n//8JwBvvvlm988XXnghBQUFALz99tt87GMf697k9OMf/zhvvfUWl1xyCZMmTWLWrFkAzJgxg7PPPhsRYdasWX0+H+eccw4jRowA4OWXX+aZZ57h7rvvxu/309HR0R382dXzcU+aNIm5c+d2P77gOGbPns2nP/1pLrvsMi677LKw7kMpNfw1uD04dYGOigHNhMVAYWEhDQ0NR5xWX19PUVFR9+/p6ekAOJ1OvF5vv7cXOr3Xm547uQdv2+FwdP8c/L23+wq9/u7du7n77rt57bXX2LBhAxdeeOER7Rf6GndvgWd/4+45rtAx9/V8hI7TGMNTTz3FunXreOedd6ioqOD4448/6jopKSn4/f7u30MfS1/PW8/H99xzz/GlL32JNWvWsGDBggGPl1Lq2OLu9OHu0vcFFb1hlwnrL2MVjnAagmZnZzNmzBhee+01zj77bOrr63nxxRe55ZZbIrrvadOmsWfPHnbs2MHkyZN5+OGHOeOMMyK6rYE0NzfjcrnIy8vj4MGDvPDCCwPuFH/66afzyCOP8P3vf58XXnihOwA9/fTTue6667jtttswxvD000/z8MMPx2Sc5513Hvfccw/33HMPYC1kmDdvHjk5ObS0tHRfbuLEiTz77LMArF27lt27d4d1P36/n8rKSs4880wWL17Mo48+Smtr61HZRKXUscvt8eLujHxRlFJBmgmLkb/+9a/8+Mc/Zu7cuZx11lnccccdlJeXR3RbGRkZPPjgg3zqU59i1qxZOBwObrrpphiP2DJnzhzmzZvHjBkzuP766zn11FMHvM4dd9zBm2++yfz583n55ZeZMGECAPPnz+e6667jhBNO4MQTT+SGG25g3rx5MRnnD37wA7q6upg9ezYnnngiP/jBDwA488wz2bJlS3dh/ic+8Qnq6+uZO3cuv//977undO3y+Xxcc801zJo1i3nz5vH1r39dAzClVDdjDG6PD7fHl+ihqGFABpr6SjYLFy40q1evPuK0rVu39jo1FQ3dtih5JcOxicdrbrhYtmzZgNlUlRh6bKLX6fVx3PdfJDcjhQ0/PC+mt63HJ3lFc2xEZI0xZmFv52kmTCmllLKpPZABa+/STJiKXlyDMBE5X0S2icgOEbmtl/OXiEiTiKwL/Ou9p4JSSimVBNoCQViXz+Dx+ge4tFL9i1thvog4gXuBc4AqYJWIPGOM6dlc5S1jzEXxGodSSikVK+0eb8jPPtJSdEJJRS6er54TgB3GmF3GGA/wGHBpvO5sqNW2qaFLX2tKHbvaOg9PQ2qbChWteAZhJUBlyO9VgdN6OllE1ovICyISUX+JjIwM6urq9MNRxZ0xhrq6OjIyMhI9FKVUAoSuitQVkipa8ewT1ls74Z5R0lqg1BjTKiIfBf4FTDnqhkRuBG4EGDVqFMuWLet5Pi6Xi8rKyp5XjZgxps9O+CqxEn1sfD4fbW1t7N27N2FjSGatra1H/Y2q5KDHJnrrag5nv956dwWVebHrF6bHJ3nF69jEMwirAsaH/D4OqA69gDGmOeTn50XkdyJSZIyp7XG5+4H7wWpRMRhLeHWpcPLSY5Pc9PgkLz020WtZXw1rrT1xp8+exwmTRsTstvX4JK94HZt4TkeuAqaIyCQRSQOuBJ4JvYCIjJZASkNETgiMpy6OY1JKKaUi5g4pzG/zaE2Yik7cMmHGGK+IfBl4CXACfzbGbBaRmwLn3wd8ErhZRLxAO3Cl0cIupZRSSSq0ML9da8JUlOK6d6Qx5nng+R6n3Rfy82+B38ZzDEoppVSshDZp1cJ8FS1tcKKUUkrZ1NYZ2idMpyNVdDQIU0oppWxye3ykOqX7Z6WioUGYUkopZZPb46UgKw04vIWRUpHSIEwppZSyye3xkZ2eQmaqU6cjVdQ0CFNKKaVscnt8ZKU7caU7dTpSRU2DMKWUUsomt8dLVmoKmWlObVGhoqZBmFJKKWVTMBOWlZqimTAVNQ3ClFJKKZvaOr240qxMmHbMV9HSIEwppZSyqd3jIzPNSZZOR6oY0CBMKaWUsqnN48OV5iQrTacjVfQ0CFNKKaVssjJhKVYmrEuDMBUdDcKUUkopG7p8fjw+fyAT5sStNWEqShqEKaWUUjYEpx8z05xkpjlxd2omTEVHgzCllFLKhmDmy5VuTUe6u3wYYxI8KjWUaRCmlFJK2RDMhGUFCvN9foPH50/wqNRQpkGYUkopZUNw+jErUJgPaJsKFRUNwpRSSikbuqcjA4X5YLWsUCpSGoQppZRSNhxZmJ8CQLuukFRR0CBMKaWUsqEttDA/1cqEacNWFQ0NwpRSSikbujNhqU6y0jUIU9HTIEwppZSywd0Z2qIiOB2pQZiKnAZhSimllA3urtAWFcHCfK0JU5HTIEwppZSywd3pwyGQnuIgU2vCVAxoEKaUUkrZ4Pb4yEpLQUS0T5iKCQ3ClFJKKRvcHm938OVKTwmcpkGYipwGYUoppZQNVibMCsLSUxyIaJ8wFR0NwpRSSikbrEyYlQETEbJSndoxX0VFgzCllFLKhrZOH65AfzCAzLQUnY5UUdEgTCmllLLB3eXr3q4IrFYVOh2poqFBmFJKKWWDu9OLK+1wJiwrzamZMBWVAYMwEUm3c5pSSik1nLk9PjJ7BGHtXRqEqcjZyYS9Z/M0pZRSathye7y4jpiOTKGtU6cjVeRS+jpDREYDJUCmiMwDJHBWLpA1CGNTSimlkkZoiwqAzDQnta2dCRyRGur6DMKA84DrgHHAL0NObwG+F8cxKaWUUknF5zd0ev3dLSpApyNV9PoMwowxDwEPicgnjDFPDeKYlFJKqaTiDqyCzDqiJkxbVKjo9JcJC3pWRK4GJoZe3hhzV7wGpZRSSiWTYLCVld6jMF+DMBUFO0HYv4EmYA2gk99KKaWOOcECfFeP6cg2jxdjDCLS11WV6pOdIGycMeb8uI9EKaWUSlLBTFhmj8J8Y6DT6ycj1dnXVZXqk50WFe+KyKy4j0QppZRKUsEgLDQTFvxZ68JUpOxkwhYD14nIbqzpSAGMMWZ2XEemlFJKJYlgYX7PTFjwvBGutISMSw1tdoKwC+I+CqWUUiqJdWfCehTmA1qcryI24HSkMWYvMB44K/Cz2871lFJKqeGie3Vk6pGF+QBtGoSpCNnZO/IO4DvAdwMnpQJ/i+eglFJKqWTS3ScsJBOWmZpyxHlKhctORutjwCVAG4AxphrIieeglFJKqWTSnQkLqQkLTk3qdKSKlJ0gzGOMMYABEBFXfIeklFJKJRd3pxcRyEg5uiZMV0eqSNkJwp4QkT8A+SLyeeBV4AE7Ny4i54vINhHZISK39XO5RSLiE5FP2hu2UkopNXjcHh9ZqU4cjsNNWTPTdDpSRWfA1ZHGmLtF5BygGTgOuN0Y88pA1xMRJ3AvcA5QBawSkWeMMVt6udzPgZciGL9SSikVd20eX3fQFZSVqpkwFR07LSowxrwiIiuClxeREcaY+gGudgKwwxizK3Cdx4BLgS09LvcV4ClgUTgDV0oppQaL2+M9oj0FhPYJ0yBMRWbAIExEvgDcBbQDfgLNWoGyAa5aAlSG/F4FnNjjtkuwCv/Pop8gTERuBG4EGDVqFMuWLRto2FFrbW0dlPtR4dNjk9z0+CQvPTaRq6juwO8xRzx/xhgcAh9s38UyqYr6PvT4JK94HRs7mbBbgRnGmNowb7u33UxNj99/DXzHGOPrb/NTY8z9wP0ACxcuNEuWLAlzKOFbtmwZg3E/Knx6bJKbHp/kpccmcg/sWE5xpp8lS0454nTXspcYOWYcS5ZMj/o+9Pgkr3gdGztB2E6sBq3hqsJq8ho0DqjucZmFwGOBAKwI+KiIeI0x/4rg/pRSSqm4cHt8ZKcf/ZGZmebUwnwVMTtB2HexNvFegbV3JADGmK8OcL1VwBQRmQTsA64Erg69gDFmUvBnEfkL8KwGYEoppZKNu9NHcU76UadnpTm1JkxFzE4Q9gdgKbARqybMFmOMV0S+jLXq0Qn82RizWURuCpx/XwTjVUoppQadu8tLVlpvmbAUDcJUxOwEYV5jzDciuXFjzPPA8z1O6zX4MsZcF8l9KKWUUvHm7vQd0S0/yJXmpL1LpyNVZOw0a31dRG4UkTEiMiL4L+4jU0oppZKE2+PD1WdNmGbCVGTsZMKCdVzfDTnNTosKpZRSasjz+Q3tXT4yU4/OhGWlOalp7uzlWkoNzE7H/EkDXUYppZQartq7rExXz2atAFlpKbh1OlJFqM8gTETOMsYsFZGP93a+Meaf8RuWUkoplRyCLSh6bltkneakXacjVYT6y4SdgbUq8uJezjOABmFKKaWGPXdnIBPWR2G+1oSpSPUZhBlj7hARB/CCMeaJQRyTUkoplTSCQVZvqyMz01Jo7/Lh9xscjr53flGqN/2ujjTG+IEvD9JYlFJKqaQTnI7srU9YVpoTY6DDq9kwFT47LSpeEZFbRWS8tqhQSil1rOkvExY8TackVSTstKi4PvD/l0JO0xYVSimljgn9ZcKCbSu0OF9FQltUKKWUUv0IZrl6a1ERbOCqmTAViQGnI0UkS0S+LyL3B36fIiIXxX9oSimlVOK1BQKszF4L84PTkdorTIXPTk3Yg4AHOCXwexXw47iNSCmllEoi7k4rwHL1VpifqjVhKnJ2grByY8z/AF0Axph2QNfhKqWUOiYEA6zety3S6UgVOTtBmEdEMrGK8RGRckA3ylJKKXVMcHu8ZKY6e+0DptORKhp2VkfeAbwIjBeRR4BTgeviOSillFIqWbg9vl7bU8DhYn1dHakiYWd15CsishY4CWsa8hZjTG3cR6aUUkolAbfHR1YvKyMBslJ1OlJFzk4mDKx9JBdjTUmmAk/HbURKKaVUEnF7vN3BVk86HamiYadFxe+Am4CNwCbgCyJyb7wHppRSSiWD/jJhaSkOUhyimTAVETuZsDOAmcaYYGH+Q1gBmVJKKTXs9VcTBlY2TIMwFQk7qyO3ARNCfh8PbIjPcJRSSqnk0tbp7XXLoiBXWooW5quI2MmEFQJbRWRl4PdFwHIReQbAGHNJvAanlFJKJVp7lw9XP5mwrDQn7i4NwlT47ARht8d9FEoppVSSauv0kdlPJiwzzdndVV+pcNgJwg4ZY7aEniAiS4wxy+IzJKWUUip5uD3egTNhOh2pImCnJuwJEfm2WDJF5B7gv+M9MKWUUirR/H5De1f/hflZaSk6HakiYicIOxGrMP9dYBVQjdU1XymllBrWOrw+jIGs9L4njrLSnLRrnzAVATtBWBfQDmQCGcBuY4w/rqNSSimlkkBwmnGgFhVtnZoJU+GzE4StwgrCFmF1zb9KRJ6M66iUUkqpJODuDAZhA2TCdDpSRcBOYf7njDGrAz8fAC4Vkc/EcUxKKaVUUnB3WdOMA9aE6XSkioCdTNgaEblGRG4HEJEJWA1clVJKqWGtrXPg6cisNCcdXX78fjNYw1LDhJ0g7HfAycBVgd9bAN07Uiml1LAX7ITvGqAwH9ApSRU2W6sjjTFfAjoAjDENQFpcR6WUUkolgbbANGNman+F+SlHXFYpu2ytjhQRJxDcwHskoKsjlVJKDXvBWq9+M2GBAE33j1ThshOE/QZ4GigWkZ8AbwM/jeuolFJKqSRgp0VF8Dztmq/CNeDqSGPMIyKyBjgbEOAyY8zWuI9MKaWUSjC3ncL8QJZMgzAVLjstKjDGfAB8EOexKKWUUknlcCbMRmG+BmEqTHamI5VSSqljktvjJT3FgdMhfV4mWLSvhfkqXBqEKaWUUn1we/rfvBs0E6Yi128QJiJOEXl1sAajlFJKJZM2j7ffqUg4PFWpNWEqXP0GYcYYH+AWkbxBGo9SSimVNNo9PlzpA2TC0oOrI3U6UoXHTmF+B7BRRF4B2oInGmO+GrdRKaWUUkmgzePrbsbaF+0TpiJlJwh7LvBPKaWUOqa4O724BqgJS3E6SHM6aNMgTIXJTp+wh0QkE5hgjNGNu5VSSh0z3B4f+VmpA14uM81Ju05HqjANuDpSRC4G1gEvBn6fKyLPxHlcSimlVMK5bRTmg7VCUgvzVbjstKj4IXAC0AhgjFkHTIrbiJRSSqkkYadFBQSCsC4NwlR47ARhXmNMU4/TjJ0bF5HzRWSbiOwQkdt6Of9SEdkgIutEZLWILLZzu0oppdRgsIIwO5mwFC3MV2GzU5i/SUSuBpwiMgX4KvDuQFcSESdwL3AOUAWsEpFnjDFbQi72GvCMMcaIyGzgCWBauA9CKaWUijVjTGA6cuBMWGaak7ZOrQlT4bGTCfsKMAPoBP4ONANfs3G9E4AdxphdxhgP8BhwaegFjDGtxphgVs2FzQybUkopFW+dXj9+c7gPWH+y0py063SkCpOd1ZFu4P+JyM+tX02LzdsuASpDfq8CTux5IRH5GPDfQDFwoc3bVkoppeIqWGjvslmYX9WgQZgKz4CvLBFZBPwZyAn83gRcb4xZM9BVezntqEyXMeZp4GkROR34EfCRXsZwI3AjwKhRo1i2bNlAw45aa2vroNyPCp8em+Smxyd56bEJzyG3H4CKXdtZ5tnT72Wb6ztpaPZF9fzq8Ule8To2dmrC/gR80RjzFkCgeP5BYPYA16sCxof8Pg6o7uvCxpg3RaRcRIqMMbU9zrsfuB9g4cKFZsmSJTaGHZ1ly5YxGPejwqfHJrnp8UleemzCs+1AC7z5JvNnz2TJ7DH9XnZp0yY2N1RH9fzq8Ule8To2dmrCWoIBGIAx5m3AzpTkKmCKiEwSkTTgSuCI/mIiMllEJPDzfCANqLM7eKWUUipegntB2i7M19WRKkx2MmErReQPWEX5BrgCWBYImjDGrO3tSsYYr4h8GXgJcAJ/NsZsFpGbAuffB3wCuFZEuoB24IqQQn2llFIqYYI1Ybb6hKWm4PH68fkNTkdv1ThKHc1OEDY38P8dPU4/BSsoO6uvKxpjngee73HafSE//xz4uZ2BKqWUUoPpcBBmrzDfuo6XnIyBtzlSCuytjjxzMAaijl0dXT6+/Oj7XHfKRBZPKUr0cJRSCgiZjrTToiJwmXaPT4MwZZudmjCl4ur+N3fx6taDvLX9UKKHopRS3cKajgxcRuvCVDg0CFMJta+xnd8t2wFAbasnwaNRSqnDgh3w7UxHZqZalwlmz5SyQ4MwlVA/fX4rAGPzMqhr60zwaJRS6rD2CDJhun+kCoedwnxE5BRgYujljTF/jdOY1DHivZ11PLdhP1//yFTWVTZoJkwplVTaPD7SnA5SnQPnKw4X5msQpuwb8JUlIg8DdwOLgUWBfwvjPC41zHl9fu78z2ZK8jP5whllFGanU9uqmTClVPJo93htFeXD4SlLDcJUOOxkwhYC07V/l4qlR1ZU8MGBFu67Zj4ZqU4Ks9Ooa/VgjCHQv1cppRKqzeMjK9VuEHa4RYVSdtmpCdsEjI73QNSxo77Nwy9e3sapkws5b4b10ipypePx+Wnp1DcwpVRycHu8ZKXbqtrR6UgVETuvriJgi4isBLrni4wxl8RtVGpYu/vlbbR5fNxx8YzurFdhdhoAda0ecrXHjlIqCbg9PltF+WBtWwRamK/CYycI+2G8B6GOHZv2NfH3lRVcd8pEpo7K6T69MDsdgLrWTiYVuRI1PKWU6ubutB+EaU2YikS/QZiIOIB7jTEzB2k8ahgzxvDDZzYzIiuNr31k6hHnFbqsTJiukFRKJQt3l5finAxbl3U6hPQUB+4uLalQ9vVbE2aM8QPrRWTCII1HDWPPrK9m9d4Gvn3+ceRlHjnlWBTMhGmvMKVUkggnEwZWXZi7UzNhyj4705FjgM2BmrC24IlaE6bC0dbp5afPb2X2uDw+tWD8UeePcB2uCVNKqWQQTk0YWFOSOh2pwmEnCLsz7qNQw95vX9/BweZOfvfpBTgcR7egSEtxkJuRQp32ClNKJYk2j9fWlkVBmWlO2nU6UoVhwFeXMeaNwRiIGr5217bxp7d28/H5JSwoLejzckXZ6dS2aSZMKZV4xhjaPT5cNpu1ArjSnJoJU2EZMAgTkRYg2Kg1DUgF2owxufEcmBo+fvzsFlKdwm3nT+v3ckXZ6ZoJU0olBY/Pj9dvws6EaRCmwmEnE5YT+ruIXAacEK8BqeHl9Q9qeO2DGr57wTSKc/tfZVSYncaOmtZBGplSSvUtWGAfbk1YTUtHvIakhiE7HfOPYIz5F3BW7IeihhuP189dz26hrMjFf506acDLF2an6f6RSqmk4O4KPwjTTJgKl53pyI+H/OrA2ktS95FUA3puYzW7a9t48LpFpKUMHO8XutJpcHfh9flJcYb9/UAppWLGHdhCLZzpyKxUp3bMV2Gx8+q6OORnL7AHuDQuo1HDypq9DWSnp3DG1JG2Ll8U2Lqo3u2x3SBRKaXiIZjRCicT5krXFhUqPHaCsD8aY94JPUFETgVq4jMkNVysr2xiVklery0penN46yINwpRSidXmCT8TlpmmmTAVHjtzPvfYPE2pbh1dPj440Myc8fm2r1OoDVuVUkmiPYJMWFaqE4/PT5fPH69h8eKmAzy7oTput68GV58hvoicDJwCjBSRb4SclQvYf1WqY9LW/c10+QxzxuXZvk6hbl2klEoSbYEgLJw+YZmBgM3t8ZGXGZ+61ntf34Hb4+Wi2WPjcvtqcPWXZ00DsgOXCW1T0Qx8Mp6DUkPfhqomgLAyYcGaMN3EWymVaO0RTEcGL9vu8R21P26sVDW4ae300uXzk6oLmIa8Pl9dgU75b4jIX4wxe0XEZYxp6+vySoVaX9nIyJx0xuTZr+3KzUglxSHasFUplXBtEfQJC2bN3J74bF3U2umlwd0FQGW9m7KR2XG5HzV47ITRY0VkC7AVQETmiMjv4jssNdStq2pkzrg8ROwV5QM4HMIIV5rWhCmlEs4dSWF+6uHpyHiorHd3/7zrkOZEhgM7QdivgfOAOgBjzHrg9DiOSQ1xzR1d7DrUxpxx+WFftzA7XWvClFIJ5/b4SHGIrR6HQcGALV5BWFVDe/fPOw/p7iLDga1XlzGmssdJugZX9WljBPVgQUXZaVoTppRKOLfHF9ZUJIQW5sdnOjKYCctIdWgmbJiwE4RVisgpgBGRNBG5lcDUpFK9WVfZCMDsMFZGBhVpJkwplQTcHm9YU5FwuH4sXr3CKhvcZKU5mV2Sr5mwYcJOEHYT8CWgBKgC5gJfjOOY1BC3oaqRiYVZ5GelhX3dQlcatS2aCVNKJVabx0dWGO0pAFyDMB05viCL8mIXu2o1EzYcDBiEGWNqjTGfNsaMMsYUA18Bbo7/0NRQtb6yKaKpSLBqwtq7fHFL5yullB3tSTodOX5EJuUjs6lv81Dfpl9Yh7o+gzARGS8i94vIsyLyORHJEpG7gW1A8eANUQ0lB5s7ONDcwewIivIBCrO1a75SKvHaOiOfjoxHJswYw76GdsYVZFE20gXALp2SHPL6y4T9FajG2qJoJrAca0pytjHmlkEYmxqC1gfqweaOD78eDEIbtmpdmFIqcdq7fLjCzYTFsUVFU3sXLZ1exhVYmTDQNhXDQX9h/ghjzA8DP78kIgeBRcYY/XRUfVpf1YjTIUwfE1kQVug6vIm3UkolSlunl/EFWWFdx+EQMlIdtHfFPgirrLfaU4wfkcW4gizSnA4tzh8G+s21ikgBEOy2eQDIEhEXgDGmPs5jU0PQhqomjhuV010bEa7u6UhdIamUSqBIasLAKs6PR01YVYPVnmJcQSZOhzCxKIudmgkb8vqbjswD1oT8ywXWBn5eHf+hqaHG7zesr2yMuCgfDmfCkrFX2AcHmnlp84FED0MpNQjaIgzCMtOcuDvjkAkLBGHjR1jZubKi7KStCWvr9PLgO7vx+02ih5L0+gzCjDETjTFlxphJvfwrG8xBqqFhT10bzR1e5kTQHywoM82JK82ZlNORv126g1seex+fvrEoNey5PV6y0sMrzAerOD8eNWGV9e3kZaaSm2FtDF5e7KKi3k2Xzx/z+4rWv9dVc+d/trC+qjHRQ0l6ugW7ipkNUXTKD5WsWxftrXPT0eVP2m+fSqnY8Hj9dPkMWamRZMJScMehJqyqwc24gszu38uKsvH6DXvr3P1cKzE2VVufBdWNHQkeSfLTIEzFzLrKRjJTnUwpzo7qdgqzk28Tb2MMe+qs+ovgG4xSangKdryPKBOW6qQ9DjVhlYFGrUHlxcEVksn3pXDzvmAQ1j7AJZUGYSpmNlQ1MrMklxRndC+rQld60rWoaHR30dJhvbFu2tec4NEopeLJ3WX9rUdUmJ8e++lIY8zRmbBAr7BkK87v8vnZeqAFgH0ahA3I1qeliCwWkf8K/DxSRCbFd1hqqOny+dlU3cycCJu0hhqZk0ZdknWCDmbBHAKb9mkmTKnhrC1QWB9ZYX5KzIOw2lYPHV3+7qJ8gNyMVEbmpCddJmxHTSser1WnppmwgQ0YhInIHcB3gO8GTkoF/hbPQamhZ9uBFjxef9T1YGBlwurbPEm1siZYd3HipEK2VDcn1diUUrEVnI50hdkxH6zpyFi3qDi8MjLziNPLilxJ1yss+CV1wogsqps0CBuInUzYx4BLgDYAY0w1kBPPQamhJ7gKJhaZsMLsNHx+Q2N7V8S30en18eSaqpgFS3vq2hCBC2aNpqXTS0V98hXDDiVrKxo0o6iSVpsn8unIzDisjqysD/YIO7J5bHlxNjsPtWFM8nwp3FzdjCvNyamTi7Qw3wY7QZjHWEfYAASbtSoVan1lIwVZqUd9U4tEYXawa37kdWEvbz7Irf9Yz5qKhqjHA1BR52ZMbgbzJxQAWpwfrW8+sZ47/7M50cNQqldRFeanObuvHytVDVZGKbQmDKB8ZDZN7V1JtZH3pn1NTB+by7iCTOrbPDF/LoYbO0HYEyLyByBfRD4PvAo8EN9hqaFmQ1UTs8flIyIDX3gARa7g/pGRv7HsDdRw7ayJTap+T10bpYUupo7KIdUpWpwfhUa3h921bXx4sDWpvsErFRRNJsyVnoLXb7rromKhqsFNUXbaURuKd2/kXZscxfk+v2HL/mZmjM2jJN8KGHVKsn8DBmHGmLuBJ4GngOOA240x99i5cRE5X0S2icgOEbmtl/M/LSIbAv/eFZE54T4AlXhtnV4+PNgSk3owCMmERdErLDhdGKt6ib11biYWZZGW4uC40Tls1kxYxIL95Jrau5JyZwSl3NEU5ndv4h27urCqhnZKetnHcnJgI+9YfdmM1u7aNtweHzNL8hgbDMK0OL9ftnKtxphXgFfCuWERcQL3AucAVcAqEXnGGLMl5GK7gTOMMQ0icgFwP3BiOPejEm/Tvib8BuaOj7xTfqju/SOjyoRZQdiuGCzfbunooq7Nw4QR1rfOmWPzeGnzAYwxMcn8HWvWVzZ2/7y9poWROemJG8wg++3S7eypc3P3p/T7ZjJzd2fCIpuOtG7DR354+3/3qbLezcySo99fx+ZnkpbiSJpMWPDL6cySXLIDU7kahPXPzurIFhFp7vGvUkSeFpH+ti86AdhhjNlljPEAjwGXhl7AGPOuMSZYtLMcGBfpA1GJE8xszI5BUT5AQVYaItHVhFXGMBMWDOgmFlrvqDNK8mhwd1HdpEWnkVhf1UR+lrX1yo4k+QY/WJZ+UMMLG/frNGySa/NE06LicBAWCz6/YV9j+xHtKYKcDrFWSCbJ39GmfU2kpziYPDKbUbkZOAT2NWgQ1h87NWG/BL4FlGAFSbdi1YQ9Bvy5n+uVAJUhv1cFTuvL54AXbIxHJZl1VY2U5GdSlB2bjIbTIYzISqM2wmLTTq+P/c0dpKU4qGxop9Mb3ZthMAgrLQxmwnIB7RcWCWMM6yobOfO4YnLSU465IKyivp02j4+DzcnVjFgdqd3jwyGQnhJ+4+lg9ixWBek1LR10+cxRRflBZSNdSZMJ27SvmWljrIbdqU4Ho3Iz2KcrJPtlJ9d6vjEmdIrwfhFZboy5S0S+18/1epun6fXrn4iciRWELe7j/BuBGwFGjRrFsmXLbAw7Oq2trYNyP8PBiu1uJuU5Yvp8ZUgX2/bsY9myuqPOG+jYHGjzYwxMzRc21fp58sU3KMmOvIv/6zutYLBiyxpqPhQ8PoND4Nl3N5B+6IOIbzce/Maw/pCP6SOcpKckZqq0v+NT1+6ntrWTrI5DFGf4WbWtkmXLagd3gAnS4TXdO0H889V3mF4YfpYlWvq+Zs+2XZ2kO+GNN94I+7rb66zg692Vq6nbEd4x7u34bKu3bq+hcjvL2ncfdR2n28Peui5eXfo6KY7ElUcYY1hX4eakMSndj8ElHrbsqWbZstisUk+keP3t2AnC/CJyOVZxPsAnQ87rL6deBYwP+X0cUN3zQiIyG/gjcIEx5uhPXMAYcz9WvRgLFy40S5YssTHs6CxbtozBuJ+hrq61k9oXX+XzS6aw5IzymN3uhA+X0+Xzs2TJKUedN9CxWbatBt5axcdPOo5Nz26hcOJ0lswcHfFYnq9dT1H2Ic7/yJndp03Z8CatKRksWXJCxLcbD0+uqeL/XlrPSWUjePC6E7qnRgZTf8fnxU37gbV88syFeFZU8Pq2Q8fM39kHB5rh1bcAyBlbzpKTJw76GPR9zZ4X6zaQ21AT0XOVV9EAq95l6vRZLJlWHNZ1ezs+dWuqYOV6LlxyMpOKju4Q1ZBXxX92rmfizIVMLk5cC8+9dW20v7SMcxcdz5ITJgDw1P732VDVOCxec/H627GTHvg08BmgBjgY+PkaEckEvtzP9VYBU0RkkoikAVcCz4ReQEQmAP8EPmOM+TCC8asEC9aDxWplZFBhduRbFwXrwZYcNxKIvi5sb527ux4saEZJLpuqk6tNhc9v+N3rOyjOSWfF7no+/9fVdHQlV4+edZVNpDqF48fkMmVUNrWtnTS6j40VkhV1hxv8Jtt+f+pIbR5fREX5cHg6MlY1YVUN7YjA2PyMXs8vD6yQ3FGT2NdUsG3PzLGHFxCMzc9gf2OH7jDSDzstKnYZYy42xhQZY0YGft5hjGk3xrzdz/W8WEHaS8BW4AljzGYRuUlEbgpc7HagEPidiKwTkdUxeExqEK2vakSEXlfuRKMoO/JNvCvq3aSnOJhU5GJUbnrUKyT31rm768GCZo7N41BLJzXNyVPv8OyGanbVtnHnJTP430/O4Z2dtXzh4TVR18TF0oaqRqaNziUj1cmUwLf2Y6UurKK763lm0m01o47U7vFGVJQPoasjY9OiorLBzaicDNJTeh9PMDu2qzaxr6lN1dYXrKmjs7tPK8nPxOPzUxtFu6HhbsBQX0QysOq1ZgDdobgx5vqBrmuMeR54vsdp94X8fANwQxjjVUlmfWUjU4qzu5cjx0pRdhotHV46unxkpIb3ZlhR72bCiCxEhPKR2VF94LV7fBxo7jgqExYMOjdVN3FWbu/fUAeT32/47dIdTB2VzXkzRuNwCF6fn9v+uZEvPbKW3316AWkRFBnHeowbqpq4bN5YACYXW2/W22taWThxRCKHNigq693kpKewoLSA1XuGfo3McNbW6Ys4CAuWALTHKAtdWe/usygfICcjlVG56exMeCasiamjco4IFsfmBXuFdVCck/j3yWRk5135YWA0cB7wBlZtV0s8B6WGBmMM66uaYrJfZE/Bhq2RbMext84KwiCwcuhQ5J3Zg9mLCT2CsOndKySTY0ryxc0H2F7TypfPmoIjUJx75QkT+NFlM3l1aw1f+ftaunyx6+AdiV21rbR2ertbmZTkZ5KZ6mT7wWMjK1RR72b8iCzKR2azr7Fdt3NJYm6PN+LpSFccpiN7a08RqqwoO6GZMGMMm6ubj5iKBLRhqw12grDJxpgfAG3GmIeAC4FZ8R2WGgqqGtqpb/MwO8b1YACFrsgathpjqAx82IFVL9Hc4Y24M3tw+6OJPaYjs9NTKCtyJUWbCmMM9yzdQdlIFxfOGnPEeZ85qZTbL5rOS5sP8rXH1+FNYCC2vtJ6ruYGXi8Oh1Be7GLHMTI1F8zQBrea2Z0kbQXU0dyeyDNhGakORMDdGf10ZJfPz/6mdsb3kwkDKC+2eoUlqv/c/qYO6ts8zCzJPeL0Eg3CBmQnCOsK/N8oIjOBPGBi3Eakhoz1VY0AzI1jJizcWoL6Ng9tHh+lhcFMWGBbjwg/6A83aj16VdKMkjw2J0Fx/qtba9i6v5kvLZmMs5cl6tcvnsT3PjqN5zbs59Z/rMeXoCLZ9VWNuNKc3YXEAFOKc9hxcPgn1v1+Q2VDOxMKs7ofv9aFJS93FIX5IkJmqjMmmbADTR34DYzrZcuiUGVF1pfNSBczRSv4ZXRGj9rg3MwUXGlO9mkQ1ic7Qdj9IlIAfB9rdeMW4OdxHZUaEtZXNnbvpRhrRRFuXdQ9fdidCQsUrUZYnL+nro38rFTyAh3eQ80cm8u+xvaIpkxjxcqCbWfCiCwunTu2z8vdeHo53zrvOP61rprvPLUhIauV1lc1MbMk74hAcXJxNtVNHbR0dPVzzaHvYEsHHq+f8SOymFTkQiQ2W2qp+HBHUZgPVnG+OwY1YcGV3uNGDJQJS+wekpuqm3EIHD/6yEyYiDA2P1MzYf3oNwgTEQfQbIxpMMa8aYwpM8YUG2P+MEjjU0lsfVUT08fkxqXgu3sT7zBXSPYMwsbmZZKR6ogqE1baRz1GsDg/kZt5v/HhITZUNfHFJeWkOPs/Dl86czK3nD2FJ9dU8f/+tXFQA7FOr4+t1c3dU5FBweL84d6yIdieYsKILDJSnZTk6wrJZNbm8ZGVHk0QlhKTmr/KBut1M37ATFhwhWRi/o4272ticnF2r30JrSAseVaRJ5t+37WNMX767wWmjlE+v2HTvqajPlRjxZXmJD3FEXZ6vfubY+BNy+EQJhVlsyvSIKy+7aj2FEHBItREFecHa8FK8jP5+Hx7265+7SNT+NKZ5fx9ZSV3PLN50GpIPtjfgsfnP6qf3JTiYI+j4R2QBL8clI44PE2e6JYCqndenx+P109WauQrvrPSnLTFoCasqqEdp0MYk9f/ysKS/EzSUxwJzIQ1HVWUH6SZsP7ZSWG8IiK3ish4ERkR/Bf3kalB1dHl4/N/Xc2f3t5tK0Oyo6YVt8fHnPGx7Q8WJCIR9QqrqHdTnJN+xDeyspGuiDItHq+ffQ3tR7WnCMrLSmX8iEw2JSgT9t7OOtbsbeCmM8psZyNFhFvPPY4bTy/j4eV7+f0bO+M8SsuGQP3g7HFHvl4mjMgizelge83wrgurrHfjkMOrxcpHuth1qE038k5CwWlEVxSZsMw0Z0xaVFTWuxmTlzFgltv6spmYPSRrWjo42Nx5VD1YUEl+BnVtnqRrHJ0s7LxzXw98CXgTWBP4p01Vh5k3PzzEK1sO8qNnt3DVA8u7M0p9WV/ZCNDdbiAeCrPTIqoJm9Bj+rB8ZDZVDe6w3wSqGtz4DX1mwsDKhm1O0ArJ/3ttO8U56Xxq4fiBLxxCRPjuBdM4YeIInl2/P06jO9K6yiaKstO6V0sFpTitpro7hnmbiop6N2PyMruD5bKR2bgDPehUcglOI0ZamG9dNzaF+ZUN7QNORQaVF0fXEzFSwcVJM8fm9np+SYGukOyPnY75k3r5VzYYg1OD58VNB8jLTOVnH5/Flupmzv/1m/x9ZUWf39TXVTWSk5HCpH4ClGgVutKoC3N1ZEVdb0GYC785vNLRrr2BQHRiUd9vgjNL8thT56Z5kAvLV+6uZ8Xuem46ozzsZrZgBWInlRfywYFmWmMwbTKQ9VWNzBmXj8jRqzcnj8oe9m0qen45CC4YSXSDTXW04DRiNIX5makpMQnCqhr6b9QaqrzIRWW9e9B3yAh+CZ3eRxAW2rBVHW3AIExEskTk+yJyf+D3KSJyUfyHpgaLx+vnla0HOWf6KK48YQIvfv105ozP57v/3Mh//WUVB3v5tr6hqpHZ4/K6G4PGQ2F2eliZsE6vj/3NHUc1Ngy2BAi3LmxvILU/YUTfgeaMwBvPlkFuVXHP0u0UZadxVWCj3EgsKC3Abw5nNeOlpaOLnYda+8yaTinOpqI+/EzlUFJR394jCAu8JrUuLOm4uzNhkQdhrnQn7VFuW9TR5eNgc+eAjVqDyouzI/qyGa1N+5qZVOQiJ+PoFeSgDVsHYmc68kHAA5wS+L0K+HHcRqQG3Ts7a2np8HLBzNGAVeT5t8+dyJ2XzGD5rjrO/dWb/Hvdvu6sWEeXjw/2t8SlU36o4HSk3bqZfQ3tGEN3j7Cg4N5q4abq99S5caU5u9tl9GZGd3H+4E1Jvl/RwFvba/n8aWW9rkayK7ioYs3e+G6hs3FfE8bQZ/3g5OJsjBm+fbPcHi+1rZ1H7LpQnJNOdnpKwgqpVd/cMZqObIsyExbsrTV+gPYUQd395wb5NbWpuqn7y2hvRudlIIL2CuuDnSCs3BjzPwSathpj2oH4pT/UoHtx4wGy01NYPKWo+zSHQ/jsKRN54ZbTKR/p4pbH1vHFR9ZS19rJ5upmvH5z1Eq3WBuZnY7H56e5w943yp7tKYJc6SmMycsIuy/T3jprZWRvU2jdY8xJZ3RuxqA2bb1n6Q4KslK55qTSqG4nLzOVqaOyWVsR3yBsQ5UVoPadCRveG3lX1gc/TA+/LkUk4gUjKr7aAhmsaFpUZKZG36KiqsF63QzUqDVoUgLaVDS6PVQ1tHe36+lNqtPBqJwMzYT1wU4Q5hGRTMAAiEg5oFuiDxNen5+Xtxzg7OOLj9h4NWhSkYt/3HQK3zl/Gq9treG8X7/Jn97eBTAomTCw3yusso8gDIIrJMOcjqx391sPFjSzJHfQMmGb9jWx9IMaPrd4Eq4YbJq+oLSAtXsb4tozbH1lIxNGZDHC1XtGcWJRFk6HDNsgLLj1VW8LRiJtnaLipz0G05FWYb43qtWvwfczu4X5wS+bg5kJO1yU3/8q+bH5GVQ3aRDWGztB2A+BF4HxIvII8Brw7XgOSg2eFbvraXB3ccHMMX1exukQbl5SzjNfOZXinAye33iAUbnpjB6gd020Cl2Bhq02e4VV1LtJT3EwMif9qPOsDzz7LQF8fmsPyv7qwYJmjM1j56FW3FHWgNhxz9Lt5GakcO0pE2Nye/MnFNDc4Y3rVOD6ysZ+s6bpKU5KR2QN2428e/YICyorclHd1DEorxuAf6yu5PFtidvdYagIFua7opiOzExz4jfQ6Y18r9bKBjdpTgfFvbyf9aVspIudg5gJC3757LlnZE/asLVvdlZHvgx8HLgO+Duw0BizLL7DUoPl+Y37yUx1csbUkQNedtroXP71pVP59vnH8c1zjov72MLNhAVXoPU2fVhW5KKl08uhFnu3Vd3YTpfP9NkjLNTMkjz8Brbuj++U5Nb9zby0+SDXnTqJ3D6KYMM1v7QAiF9dWE1LB9VNHcwZ1/835cnF2cO2V1hlvZuc9BTye2x9FdxqZjC2L1pf2ch3/7mRl/Z0xaSJ6HAW7O8VTb2lK3DdaKYkqxraKSnIDGvxU/nIbHYN4kbem6qbGVeQSX5W33WzYNUZ72ts1754vbCzOvIZ4FxgmTHmWWNMbfyHpQaDz294afNBzpw20vYbTlqKgy8umczli8LrTRWJouAm3jZXSPZcgRaqPMztcYIrjPrrERYU/BYY7875v319B640J9efOjFmt1lW5CI/KzVudWEbKq1vygPVD04Zlc3eOjeeKDIHyaqi3s34Xr4clI2MbMFIuFo6uvjK39/H4RBrNWygca7qXVtnoFlrVIX51nXboshyVtXbb08R1P1lM8wm15HatK/vTvmhxuZn4vH6E7bBeDKzMx35C+A0YIuI/ENEPiki8Z2HUoNizd4Gals7+52KTKSCLPubeBtjqKhr63M5d1lw5ZDND7y99VawZqcmbHRuBoWutLjWhe2oaeH5jfu59pSJA37rDIeIsGBCQdwyYRuqGnE6pN/VU2AV53v9prt+ajjprYEwwMTC+G/kbYzhe09vYl9jO/ddMx+A9ysa43Z/w0G7x4sIZKRGviduZowyYXaL8oMOb+Qd/7+jlo4udte2DTgVCdqmoj92piPfMMZ8ESgD7gcuB2riPTAVf89v3E9aioMzpxUneii9SktxkJeZaqtha32bhzaPr89M2JjcDDJTnbY/8PbWuUlLsVb1DEREmFGSx6Y4rpC8/81dpKc4uGHxpJjf9vzSAnYeaqMhDt9S11U1MaU4e8Dl/sGNvLcPs+J8v99Q2dB+RHuKoIxUJ+MK4ruR9z9WV/Gf9dV845ypnDVtFGNdEveWJENdm8dHVqqz31XRAwkW9UfasLWt00tdm8d2e4qgskHsPxfsjdjXdkWhxuZb76MahB3NVqgfWB35CeAmYBHwUDwHpeLP7ze8tPkAZ0wdSXYMVtnFi92ti7qLn/uo4QrurWb3A29PbRulI7Js12PMHJvL9oMtcWk42tDm4d/rqvnYvHEUZtsv0rVrQaAu7P3K2H44G2PYUNVoa5P38pHZiDDsivNrWjrxeP19ZmiDC0biYUdNC7c/s4lTJxdy0xnlAEwucLK2Ir6rYYc6t8dHVpTviZlRBmHB9hR2V0YGBb9sDkYmbJPNlZFA93Zl+7Q4/yh2asIeB7YCZwH3YvUN+0q8B5ZIx0Lx4LqqRvY3dXQ3aE1WRS57m3j31SMsVHlxtu1viHvr3LbqwYJmluTh9Rs+PBj74vJ/rKmk0+vn2pOj6wvWl9nj8nA6hLV7G2N6uxX1bhrdXbb6yWWmWVmh4bZ90UCvy7Ii6zUZ66Coo8vHlx99H1daCr+6fC7OwJeJyfkOGt1dCdnoeahwe7xRtaeAw/Vk7V2R1YRVNVivm3Brwg5v5B3/v6PN+5oYlZve62r0nvIyU8lKc2omrBd2O+aXG2NuMsYsBU4WkXvjPK6E2dfYzsd+9y6VLcOvQDjUi5sOkOoUzj5+VKKH0q/C7DRbxZzBnjr91VCUFbmoamgfMFtljGFvfZutlZFBM7s758d2StLvN/xteQUnTBzB8WMGrr2IRFZaCtPH5MZ8mmpd9ybvA39TBpg8MpvtcQhiE6mvHmFB5cUuOrr87I/xRt4/eW4rHxxo4e7L51Cce3hKfXK+FVzEu0HvUNbW6YuqWz4cno4MFvmHq7tHmM0ti0IN1kbem6rtFeWDVbJhtanQIKwnOzVhLwKzROTnIrIHa8uiD+I9sETx+vwcaOrgf1a1D7sPhCBjDC9s2s+pk4vIy4xNq4N4saYj7WXCinPS+13lWR7YHmfPAMXfNS2ddHT5+5za7M34EZnkZKSwqTq2xflvfHiIino3n4lTFixoQWkB6yob8fpi9+VjfWUTGakOpo7KsXX5KaNy2FXbhm8YTZVV1rtxyOHpmJ7KimK/1cyLm/bz8PK93Hh6GWced2S952iXkJeZylqtC+tTe1f0mbBoC/MrG9rJTHVS2EeD4/7Y/bIZjXaPjx01rbbqwYI0COtdn0GYiEwVkdtFZCvwW6w9I8UYc6Yx5p5BG+EgKy108ejnT8QhwlUPrBiW+9ltrm6msr496aciwWrY2uDuGjA46GsFWqiy4B6SA9RL7AlM1YQzHSkizBybx+YYr5B86L09jMxJ57wZ8T1W80sLaO/y8cGB2H3x2FDVyIyxeaQ67a0ym1ycjcfr784CDAcV9W7G5GWSltL7c1BeHNhqJkbvM1UNbr795AbmjMvj1nOP7uXnEGH+hHwtzu+HlQmLLggLZtIibcRb1WC1p4hkcYDdL5vR2HqgGb+xamHtKsnP0JqwXvT37vgBcDZwsTFmcSDwil9onUTKRmbznUUZGGO4+oHl3R/Kw8ULm/bjdAjnTE/+ICy4eXb9AFOSlf30CAsK9mUa6AMv2CNsYhhBGFj9wrYeaKErRtmkvXVtvPHhIa4+YUKfH+KxMn9CPhC7aSqvz8+m6qawtraaMgxXSA705WBkdjo5GSkx2UPS6/Nzy2Pr8Bu456r5fb5mFpQWsL2mlSZ3V9T3ORy1e2IRhAUK8yPMRlXWt0c0FQmHv2zGs/XJ5u5O+WFkwvIyqW3tjGuGDqyZnp2HWtm0r8nWv0Rn5/qb+P4EcCXwuoi8CDzGMbRx99hsB49+fhFX3v8eVz+wnMe/cHLEfxTJxBjDCxsPcFLZiD738ksmoQ1bQ2tbQnV6fVQ3DfymlZWWwti8jAGzm3vr20hxSPeyartmluTh8frZUdMak/qtvy3fi1OEq0+cEPVtDaQkP5NRuems2dvAtSdPjPr2PjzYSkeXnznj7b9Jl3cHYS2cMz25axXtqqhv5+x+WsBYG3nbXzDSn1+/up01exv4zVXzem2JETR/wuHVsEuOS872NInU5vFG1agVID3FgUOimY50s2hiQUTX7W4CHMcvM5v2NTPClcaYMLauC/YKO9DUwcSi8L7ghmP5rnquemC57ctfc9IEfnzZrLiNZyB9vtKMMU8DT4uIC7gM+DowSkR+Dzwd2M5oWDtudA5/u+FErn5gBVcFArG+ajuGig8PtrKrto3r49BvKh6CLRn66xW2r6EdY/puTxHKWiE5wHRknTUVkGJzGi0o+K1w076mqIOwdo+PJ1ZXcd6M0YzqI/iMJRFhQWnsmrYGu7KHkwnLzUhldG4GO4ZJmwq3x0tta2e/ARFA+UgX7+6oi+q+3tlRy73LdnDFwvFcMmdsv5edMz4fh8DavRqE9abd4yMrPbpMmIiQlZYSUWF+U3sXLR3esBu1BgW/bMZzBeym6iZmjM0Na7o0tGFrPIOwt7YfwukQ7r16Hg4b44v0eY6VAcN9Y0wb8AjwiIiMAD4F3AYM+yAMrM2Z//a5E7n6j8utjNiNJ8d94+p4en7jfkTg3BlDI9NweP/Ivqcj7bSnCCorcvHkmiqMMX2+geytawurHixoUqELV5qTzdXNfCrsax/pP+uraWrvintBfqj5Ewp4fuMBapo7+sw62rW+spG8zNSwFjeAtX3RcGlTUVkf6PU0wOuyfGQ2/1y7j9ZOb0Q9+2pbO/na4+soK3JxxyXTB7y8Kz2F48fkskZXSPaqzeONenUkWMX5kbSoOLwyMvIv/PFcIdnp9fHhwRZuOK0srOsd7hUW3+m/lbvrmVWSx/lJuhNMT2F91TfG1Btj/mCMOSteA0pGs8bl8dfrT6Cu1cPVDyynpsV+ceH+pnb++NYu7n5pW1L0H3tx0wEWlY6g2EYn+GRQ5ApOR/adCasMIwgrL86mzeOjpo+NvI0x7K11h9WeIsjhEKaPzY16+yJjDA+9t4fjRuVw4qQRUd1WOIKbeceiLmx9VRNzxueHXVhcPjKbHTWx75uVCHa/HJQHpo92R1jD850nN9DU3sVvr55vO3hYUFrAuorGYbUSNRZ8fkNHlz/qmjCw6sIiadZ6uEdY5BmasiIXuw61xeUzZ/vBVrp8xnZ7iqBReemIQHUci/PbPT7WVzUO6vtmtOJb7TuMzJtQwF/+axEHmju4+oEV/QYFNS0dPPTuHj75+3c5+b+X8uPntvLb13fw3q7ophyitfNQK9sOtnDBrOQvyA/KzUwhxSH99gqrqHeTnuKw1TRwoJYADe4uWjq9EWXCwMqcbtnfHNWH29qKRjZXN/OZk0uj2jolXDPG5pKW4oh6SrLTZzWtnWOzP1ioKaOycXusGr+hLtgjrHTABSORbzWzp7aN1z6o4Zazp4Q1BT5/QgFtHh/bYrgadjhoDxSNxyIIy0yNNAiLrFt+qPLibFo7vX1+2YxG8EvmrDCK8gHSU5yMzE6PayH8+xUNdPkMJ5ZpEDYsLZw4gj9ft4iqBjfX/HHFESv26ts8PLJiL1fdv5yTfvoadzyzmZYOL7eeO5UXv3Ya+Vmp/PXdvQkcvZUFAzh/CLSmCBKRAXuFBVeg2QlYgi0BdvZRLxFc1h3uNFrQzJI83B4fu6Oox3j4vT3kpKfwsXklEd9GJNJTnMwuyYs6CKto9uPzm7DqwYKmFFs9xXYMgxWSlfVuctJTyM/qvxdfaWEWDomskPqFwN/0ZWG+VoJbVemU5JHcndb0YSymI13pKREV5lfWu8nJSCFvgNdNf8oDgX08piQ3VTeRk5ES0XTp2PzMuH7BWrG7HhHrs3qoSN5NA5PUSWWF/Omzi7j+L6u45o8r+OwppTy38QDv7KjF5zeUFbn48llTuHj2GKaENKm8YtF4/vjWbvY3tTMmLzHF/S9s2s+8CfkJu/9IFbrSB6gJG7g9RdDo3Ayy0px9fuB1Zy8izITNLLGyEZurm7o3pQ7HoZZOnt94gKtPnIArAXt6Ligt4MF39tDp9ZGeElk2YFeT1aJjdhgrI4OCz9mOmtYhXzReUe9mvI0vB+kpTsaPyOrzi0F/Xty0nznj88NeMDSuIJOROems3dvAZ04avLrDZBfMXMVqOrK1M/yasKqG9qiyYBCyQvJQG6eUF0V1Wz1t2tfMzLF5EWXpS/Iz2XogtruKhFqxu47pY3LJzUjuJuShNBMWgVMnF/GHzyxgR00r33lqI7trW7nx9DKe++piXvvmGXzjnKlHBGAA15xYit8YHl1RkZAxV9S52bSveUg0aO2pMDuN2j6mI40xVAY+7OywWgL0vZH3nlo3IpEXxU4emU16iiPiurDHV1Xg8fm5JkEfjPNLC/D4/FFtv7Sr0cfYvIyI6g5HuNIodKUNi4287TQQDiofmR12Jqyqwc36qqaI/qZFhAUTYrcadrho88QuE5aZ6owsExZo1BqN4JfNWDUBDvL6/Gzd39z9ZTNcY/MzqG5sj0utWqfXx/sVjZw4qTDmtx1PGoRFaMlxxTz9pVP495dO5c1vncl3zp/GjH6+HYwfkcVZxxXz95UVdHoHv+fti5v3A3DBEFkxEqooO73P6cj6Ng+tnV7bH3YQ2DS5jyLoino3Y/MyI84CpTgdTBuTG1EQ4/X5eWRFBYsnF0WURYuFYA+paLa12d3st7Vpd18mF2ezvWZo1yr5/YbKhvYB21MElRW52F3bFtaChGB5QaRfrOaX5lNR7+ZQHOqGhqr2GGfCwq0Js75URt6oNejwl83YtqnYeaiNTq8/rCatocbmZ9LR5achDo2CN1Q10en1c8IQKsoHDcKiMmNsXlgrwD5zcim1rZ7uN8/B9PzGA8wsyR2SDWcLXWl9TkcGV6CFU8NVPjKbfY3tvX5L3VPXFnE9WNDMsblsqm4K+9veq1tr2N/UMahtKXoamZPOhBFZEWdIGto81LgNsyOoBwuaMspaIZkMq4kjVdPSicfrt/33Vl6cTafXH9by/Rc2HWD6mNyIp84XxHA17HDRFnhPcEXZJwwgMy0l7CCspctaHBBtJgys97lYZ8KCGf4ZYa6MDAr2CtvXEPu6sJW76wE0CFN9O33KSCYWZvHX96Iv0H9uw37ue2OnrX329je1s66ycUhmwcBq2Nre5et1H7ZweoQFBesleiue31vnjvhDLWhmSR4tHV42V4eXDXt4+R7G5mX022F9MCwoLWBNRUNEQVB3k9YI6sGCJo/MprnDO6QzNOG+Lru3mrFZF3agqYM1exuiKi+YMTaPNKdDN/MO0R7D6UhXmrP79uyqdVv1lNHWhIGV8d/X2B7x/pW92biviaw0J5MibLYaz15hy3fVMXVU9pDYCSaUBmGDyOEQrjmplDV7G9hcHXkvqb11bXz98XX87IUPOO1/XufSe9/hj2/tYn8fq06inbZItGDD1tqWo7NhwSA0nJ46fa0cau7oor7NE1GPsFCnTSkiJz2Fy//wHo+uqLAVzOyoaeGdHXV8+qTSsDv1x9r80gIOtXR2L5UPx4aqJoTwl6+HCtZTDuU9JMMNwoJbNtmtC3tpc+BvelbkX6wyUp3MLMnVurAQwQ73MZuO7PKF9WXmULt12VjMWJxUNgJj4Bcvfxj1bYH1HvXYKqtcwumIrHVOaNf8WPL6/KzZ2zDk6sFAg7BB96kF48lIdfBwFNmwHz27lRSn8M8vnsJtF0zD5/fz4+e2cvJ/L+VT973LQ+/uOaKh7AsbD3DcqJzufkRDTXAT79peti6qqHdTnJNOZhhvmpP62OC2oi44tRldJmxcQRYvfv105k3I53tPb+S6B1dxoKn/BoUPv7eXNKeDKxeNj+q+YyGazbzXVzYyxiXkRLE6aUrICsmhqqKuDYdge9VioSuN3IwU273CXti0nynF2VHXDs6fUMCGfU14vLHZdH6oc3f3CYtFx/wUjIGOLvvPbW27ddlYTEeeWFbIdadM5E9v7+a1rQejuq2OLh9ffvR9XGkp/OiymRHfTkFWKhmpjpgHYZuqm3F7fEOqP1iQBmGDLC8rlcvmlvCvdftoiqA4cdm2Gl7depCvnDWF+RMKuOmMcp79ymm8fusSvnnOVJrbvdzxzGZO+ulrXP3Acv709m5W7a0fUg1aewpu4t1bXVg4K9CCMtOclORnHpUJi7ZHWKiS/Ewevv5E7rp0Bit213Hur97g3+v29fqtuLXTy1Nr93Hh7DHde2Um0nGjcnClOcPOkBhjWF/VxKS86LIII3PSyclIGdLF+RX1bsbkZZKWYu8tVkSsrWZqBp6OrG3tZOXu+phktheUFuDx+qPKzMea15e4gPBwn7DYZMKAsKYDD7UbRrjSYtae5rYLpjF9TC63/mP9gF8E+/OT57bywYEW7r58TlR72YpIXHqFrQg0Qh9q9WCgQVhCfObkUjq6/PxjTWVY1/N4/dz17BYmFbm4fvHEI86bVOTiK2dP4aWvn84rXz+dL581hQNNHfzo2S0YMzRXRQZ1b+LdywrJyjB6hIUqG+k6Kuuwty78Iv/+OBzCtSdP5IVbTmdycTa3PLaOLz6y9qjH8fT71r6B1yawID9UitPB3An5YWfC1lY0UtvaSVl+dG8rIsKU4uwh3aYiki8HZUXZtjJhL28+iN9ENxUZFNyqKtFTkqG7jBz3gxd588NDCRlHsDA/MzUWhfnBIMx+cX6t2zA+BlmwoIxUJ/dcPY9Or59bHns/op08Xty0n4eX7+Xzp03izBj07ivJz2RfjLcuWrm7nrIi15DZji+UBmEJMGNsHgtLC3h4+d6wlqT/5d3d7DrUxu0XTe+3hcKUUTl845ypvPbNM3juq4v502cXctzonD4vn+wKA4WWPbcu8nj9VDdFtpzbWjl05N5qe2rbKM5Jj8lURKhJRS7+cdMpfOf8aby2tYbzfv0mLwdqeowxPPzeHmaV5DE3irYOsbZgQgFb97fQZrPZZHNHF197/H1K8jM5aUz0z9+U4pyhPR0ZwZeD8mIXB5s7aenoP0P+wqb9TCzMYloM/qZH5WZQkp/J+xWNUd9WuOrbPDy6ouKIXUaaO7oY4UrjF698mJDVse0eL5mpThwR1jyFcgXeR8IKwtr9Ue0Z2ZvykdncdelMVuyu597Xd4R13aoGN99+cgOzx+XxrfOmxWQ8JfmZMZ2O9PkNK/fUD8ksGGgQljCfObmUvXVu3thu7xtfTXMH//fqds6aVsyZNlfPiQgzxuZx9vGjohlqwmWkOslOTzlqv86qBjfGhLcyMqh8pAu3x8eB5sPfyPbWu5kYZT1YX5wO4eYl5TzzlVMpzsngxofX8M0n1vPKloN8eLB10PeJHMi80gJ8ftO92rE/xhi++8+NVDd28Jur5uJKjf5xTC7Opq7Nc8TWYEOF2+OltrXTdo+woOC+pv1tedXo9vDezjrOnzkmZq+XBaUFrN5bPyhBT1N7F/9YXcm1f17Jop+8yvee3sjB5g6+fOZkXv766bz89TP4+kemsr6ykbe218Z9PD21eXwxaU8B4U9H+v2G2nbDuAgbRffnE/NL+Ni8En796ofdrRwG4vX5ueWxdfgN3HPVPNtT6wMZm5/JoZbOmPXL/OBAMy0d3iFZDwYahCXMBTPHUJSdbrtA/+cvbsPj8/ODi6bHeWTJydo/8sgP5Eh6hAV1r5AMqcHZG4MeYQOZNjqXf33pVL561mT+tW4fNz68hvysVC6ZMzau9xuu+ePtN219fFUlz23YzzfOmcqC0ti8EU4eNXSL8yvrAxswh/nlYHJwX9N+eju9suUgXr/hozGs8VxQWsDB5k6qo6gZGsj2gy3c8NAqFv34Vb715AZ2HWrl86eV8exXAruMnHscUwOrYj+xoIQxeRn85rXtg54Na/f4wlrk05/g7djtml/T0onXxKY9RU8iwo8um8mEEVnc8tj7NNj4cvPrV7ezZm8DP/nYzKgXK4UKrpCMpkYt1IpdVlA5FFdGggZhCZOW4uDqE8bz+raaAXt9ra1o4Km1VXxucVnE/VmGukJXGnU9VkdWRtAjLCi4UjRYg+P2eDnY3Bn3IAysY/+Nc4/jqZtPYc64PL64pJyMGNSgxFJeVipTirNZO8A01faDLfzwP5tZPLmIm88oj9n9B1dIDsXi/Eh611mXd+F0SJ+7OYDVoLUkPzOqFiA9LYhzXZgxhluf3MDK3fV85uRSnv7iKbz17TO57YJpzCw5epeR9BQnN51Rzuq9DbwXKLgeLG2d3u5pxGhlhVkTVtUQbLcTn719s9NTuOeq+dS2dvKtJzf0G+C+s6OWe5ft4PKF47h0bnibww9kbL5VtxWrXmErd9czriCzO7gbajQIS6CrTyzFIcLflvedDfP7DT98ZjPFOel8+azJgzi65FKYffQm3hX1btJTHIzMCX9F4ajcdFwhG3kfzqoNXpA7d3w+//7yYm48PXbBSywtKC1gbUVDn3WLocvWf3n5nJjU0QSNzcskK805JDNhkQZhaSkOJozI6jMT1tLRxdvba7lg5uiYTl1PG51DZqozbk1b39pey/rKRm674Hh+cNF05k0oGHD8Vywaz8icdO55Lbwapmi1d/lisjISQoKwLntBWGUgCIvnriazxuVx2wXH8+rWg302Da9t7eRrj6+jrMjFDy+ZEfMxlHT3Cos+E2aMVQ82VLNgoEFYQo3Oy+Dc6aN4fHUlHX38oT65pooNVU1876PHkx2jZctDUVF2GrW9BGETRmRF9IFk7a2W3d2hPLgyMl41YUPR/NICGt1dfXZx/9GzW9h2sIVfXD6H4iiWrffG4RDKR2YPzSCsro2c9BQKssLvlVZW5OozE7b0gxo8Pn/M282kOB3MGZ8Xl+2LjDHcs3Q7Y/Iy+MQC+xmVjFQnXzi9jPd21bF6j70aplho6/TGbGFO8HbcNhe3VAWmse32lovU9adO5Kxpxfzkua1HtSbx+w23/mM9Te1d/Pbq+TFfpATW5x7EpmHr9ppW6ts8nDhEi/IhzkGYiJwvIttEZIeI3NbL+dNE5D0R6RSRW+M5lmT1mZNLaXR38cz66qPOa2rv4ucvfsCC0gIunZtcNUODrdCVTn1b5xFZmUhWoIUqH+nqzoTtDfQIC7eYejjrbzPvFzbu55EVFXzh9DKWxGDZem+GapuKino34yP8clBebH0x6K2VwPMb9zMqN515gXq9WFpQWsDm6uaYbnEDsHxXPav2NHDTGeX9rujuzdUnTmCEK43fLB28bJjbE4dMmM3pyMoGN/npEvfSBBHhfz85mwJXKl959P0jVkD/6e3dLNt2iB9ceDzHj8mNy/2npzgZmZMekyBsRWCRwVAtyoc4BmEi4gTuBS4ApgNXiUjPqvJ64KvA3fEaR7I7uayQKcXZPPze3qPm6P/v1e3Uuz3cecmMpFo5lwiF2Wn4DTS2W8v3jTFUBj7sIlU+Mpvqpg7cHi976twUZKWSlxl5p/fhpqzIRX5W6lEZksp6N99+agNzxuXxzXOPi9v9Tx6VzYHmDpoHaNmQbCLpERZUVuSyWq/0+IBq6/SybNshzp8xOqbTvkELAqthN1TFtmnrPUu3MzInnSsi2AkiKy2FG06bxJsfHmJdZWNMx9WXWAZh3YX5dqcj69spyhyc9/nC7HR+fcU8dte1cfu/NwPWbhc/f/EDzpsximtOim/PwrH5mTGpCVuxq45RuelRfRlPtHhmwk4AdhhjdhljPMBjwKWhFzDG1BhjVgFD6102hkSEa08uZeO+piPeaLYfbOGh9/Zw5aIJzIxhEe5QFWzYGmxTUd/mobXTG9UfX3dx/qG2wMpInYoM5XAI8ycUHFGw3eWzmj5i4J6r5sds2XpvJo8Mbz/FZOD3Gyob2iPOqAb3kNzRoy5s2bZDdHr9nB+npsvB7FospyRX76nn3Z11fOH0soizO9eePJH8rFR+u3R7zMbVH7fHR1aMyj7SnA6cDrGdXaxqdA9aEAZwcnkhXzlzMk+treLh9/bwlb+/T3FOOj//xOy4f+kvyc+IOhNmjGHlbqsebCgnKeJZZFQChLaErwJOjOSGRORG4EaAUaNGsWzZsqgHN5DW1tZBuR+AIq8hwwn/868VfGF2BsYY/nd1B+kOw8nZtYM2jmRWVWd9m3zt7ZWMT2/nX6++DUBz9U6WLYtsH876Fmt7lGffXMW2fR6m5Dv0ue6hwOdhaU0Xz73yOq5U4ckPPayt6OLmOens2riSXb1cJ1Z/O/VtweOzmqZxg5+hbPYYttb5WDTaicPmm3xDhx+P109HbRXLloW/X1+zx8qGv/zeemT/4cf80LoOctKgvWIDyyoj/8Dp79iMdgkvr9nBdKoivv1Qd6/uICcVxnfuZdmyiohv58yx8PTWGh565jVKc8MP5g65/Wys9TFnpJPCzP6/NLS0d1J3sJply2KzKjPNYfhw116WLTvQ7+V8fsO+hnamjzOD+h40J8UwtcDBD/69GYfAd0/IYN3Kd+N+v76WTirrvbz++usRB1AH2vzUtHRS0DU4n5HxigniGYT19sxG1PTFGHM/cD/AwoULzZIlS6IYlj3Lli1jMO4n6L22TTy2spKZC09m9Z4GttSt4YcXT+eSUycN2hiS2diDLfzPqjcZN/l4shs+xJc/BZav48IzTmTKqMg6h3d0+bj93RdxFIyjvmMnJ0wvY8mSqTEe+dCWNr6Wp7avIGvCDFIcDp57aQVXLhrPdz4xu8/rxOpvx+vzc/t7L+EcMY4lS46P+vbCUdfayVUPLOfDg25mz5xve4uglbvrYdl7nH3SXM6YOjLs+zXGcPvyV5C80SxZMguwXqdfXPoKl86dwFlnzgr7NkP1d2xOO7SeV7ce5Iwzzog6s7CuspFNL77Dt88/jvOWRLeqe96JXbz6s6W815TPZy9ZENZ199a1cdsflnOg2VrUs7C0gItmj+Gjs8cctcWN32/ofPF5jiufFLP3gdx3X2XEyGKWLOn778Xvt5od+42baSMzBvVzB+D4+e1c9cByPnNSKTecVjYo97krZTcv7dnC3BNOpSCwI0q4Hl9VAWzkM+efxOTi+O8IE6+YIJ7TkVVAaCHAOODo6nMFwLUnl+Lx+fnru3v48XNbOG5UTtzn5YeS7q2LAtORwR5h0WzxkZHqZFxBJm98eAi/id2ekcPJnHH5OB3Cy5sP8vUn1lE+Mps7Lo79svXepDgdlBW5Bn2FZKPbwzV/WsneOjejczP4zdIdtpuGRtqeIkhEAiskDz/mNz88hNvji8mG3f1ZUFpAg7ur3479dv126Xbys1K59uSJUd9WXmYq1506kRc3H2DbAft94yrr3Vz9wAo6vT4evG4R3zxnKi0dXn74ny2c9NPXuOr+5TyyYm/3rgwdgQ7usaoJs24rpd8WFcYYfvDvTTy+upKvnj2FecWDvwJ+bH4my25dMmgBWPA+IbpeYSt21VPoSutuvD1UxTMIWwVMEZFJIpIGXAk8E8f7G9ImF+dwSnkhv1m6g6qGdu64ZDopTu0gEpSflYZDDu8fWVHvpjgnPeru1mVF2WyubgYGt0fYUOFKT+H4MTn8fWVFYNn6vJh1FLdjcnH2oDZsbWrv4po/rWDnoVYeuHYht553HFv3N/Pq1hpb16+od+OQ6NoMlI/MZmdIm4oXNh0gLzOVk8vj2wspuJn3QA16B7K5uolXt9Zw/amTYtZW5/pTJ+FKc/Jbm3sfVjda2Z3WTi9/u+FEzpxWzFfOnsJLXz+dl79+Ol8+czIHmzv4f09vYtFPXuXaP6/k0RXWlKkrhq/vzFQn7X3UhBljuPM/W3hkRQVfXFLO1z8yJWb3G67Brqk63CssiiBst7Vf5FCuB4M4BmHGGC/wZeAlYCvwhDFms4jcJCI3AYjIaBGpAr4BfF9EqkQkPutih4BrT7YyXxfOGsMp5UUJHk1ycTqEEa7DvcKiWYEWKvRb1ETNhPVqQaBVxe0XTWfa6MH985xSnENlfTvf/edG3t1R22vrhlhp6eji2j+v5MMDrfzhmgWcPnUkl84dy/gRmdyz1N4WOhV1bYzJy4xqwULZyGwOtXTS3NGFx+vn1a0HOWf6KFLj/KVs8shscjJSou6c/9ulO8hJT+Gzp0yMzcCAAlca15xcyrMbqvvd1gms7XCuemA5Te4uHv7cCcwYe+TCpqmjcvjGucfx2jfP4NmvLObzp5Wx61ArP35uK2B98YiVrDRnry0qjDH85Lmt/OXdPXz+tEl867zjhnwwEY5g1/xIg7CqBjf7GtuHdH+woLjmPo0xzwPP9zjtvpCfD2BNUyrgnOmjuf2i6VxyjPcE60uhK92ajhxhLeeOxR9g2Ugr+5WTnsKICGsThrsbTivjuNG5XHVC+G0GonXtyaXsPNTKv97fx99XVjAyJ52PzhzNRXPGsmBCQczaNbR2ernuwVVs3tfE769ZwJnTrN5nqU4HX1wyme/+cyNvfHhowJ5osfhyUB54Te461EaD20NLhzeme0X2JbgaNprO+dsOtPDCpgN85azJMW/38vnTynjo3T3c+/oOfnn53F4vU9PSwdUPLKeu1cNfP3cCs8fl93l7IsLMkjxmluTxnfOPY31VEyt21XH28aNiNuas9BSa249c/G+M4X9e2sYf397NdadM5HsfPf6YCsAARrjSSE9xRLxfaXC/yBOGcKf8IJ3vSiJOh3D94kkUZYe/Dc+xoDA7jbo2D16/obqpPSbbewQzYRMKI2uueSwYPyKLq0+ckJDnp8CVxm+umsfaH5zDvVfPZ8GEAh5bVcmn7nuPU3++lB8/u4X1lY1RbfTs9ni5/i+rWFfZyD1XzeOc6Ud+CH9i/jjG5mVwj43asGgbCENo65RWXti4n5z0FE6dPDiZ8QWlBXxY0xJxb7bfvr4DV5qT6+OwoKgoO51Pn1jKv9dVdzdXDlXb2smnH1jBgeYOHvyvRd3Nhu0QEeaOz+cLZ5THNHjMSnUe1aLiV69u5/fLdvLpEydwx8XTj8n3HRGhJIpeYSt315OXmcq00fEvyI83DcLUkGHtH9lJbbvBmMiLn0MFsw66XVFyy0xzcuHsMdz3mQWs+cE5/PqKucwYm8tD7+3h0nvf4Yz/XcbPX/yAzdVNYQVkHV0+bnhoNav31POrK+b2ugoyLcXBzUvKWbO3gfd29t26wO3xUtvaGfWuC6WFWaQ4hG0HW3h5y0HOOr447G7zkZo/oQBjYF0EdWE7D7Xy7IZqrjm5NOIVbwP5wullOB3C717fecTpDW0ervnjCiob3Pzps4tYNDE5pql6Tkfe89p2fvPadq5YOJ4fXTrzmAzAgsbmZ0Y8Hblidx2LJo6IS+PiwaZBmBoyCl1p1LV6qHFb/aNisZpxZE46ZUUuFpTGfisYFR/Z6SlcNq+EP352Eav/3zn8zydnM7HIxf1v7uLC37zN2b98g1++8iHbD/Zf0N/R5ePzf13Ne7vq+MXlc7hkTt9lAJ9aOJ7inHR+00/T0MrA3n/RZmhTndZG3k+t2Ueju4sL4tSgtTdzxufhECKqC7v39R2kpzj4fBxX2RXnZnDlovE8tbaKqsCG101uazHF7to2/njtorgvYAhHZpqT9kAQdt8bO/nFKx/y8fkl/PfHZw2LACIaYyNs2HqwuYM9de5hUQ8GGoSpIaQoO42WTi/VrVamIxaZMBFh6a1LuH6x9mMbivKyUrl84Xj+ev0JrPp/H+GnH5vFqJwM7lm6nXN+9Sbn/epNfrt0O3t6tF3o9Pq4+W9reGt7LT//xGw+Nq//0tSMVCdfOKM8sBdi7xtKR9ueIlTZyGxqWzvJTHVG1G8sUjkZqRw3OjfszvkVdW7+va6aq08ojXs5xU1nlCNiBTXNHV1c++cVbD/Yyh8+s4DFU5JrQVMwE/bHt3bxsxc+4JI5Y/nfT8455gMwsDJhNS2deLz+sK43HPaLDKVBmBoyglsX7WrykZ7iYGSO1s6pw0a40rj6xAn8/caTWPG9s7nzkhnkZKRw98sfsuTuZVx0z1vc98ZO9tS28eVH3+f1bYf46cdmcflCewsOrj5hAkXZafzmtd6zYbEMwoLT5GdNKx7UliAAC0rzeb+iMayVqL9btgOnQ/jCGfHvNTU2P5NPLhjHE6uquOaPK9iyv5nfXzM/bhvJRyMrLYX2Lh8/fm4rF8wczS8vn4NTAzDAOo7GWJmtcKzcXUd2egrT47TB+GDTIEwNGcGGrTsa/UwYoYX0qm/FORl89pSJPHnzKbx721l8/8LjcYrwsxc+YMndy3hly0HuunQGV584wfZtZqY5ueG0Mt7aXsv7vWSKKuvd5KSnUJAVfWF3cMHI+XFu0Nqb+RMKaO308p2nNvDuzoHbguxrbOeptVVcuWg8o3Iz+r1srHxxyWR8xrC5upl7rpof0xWNseRKtwLoc6aP4jdXzdPejyFKImzYumJXPQtKC4bNczn47XmVilAwE1bfYZg3UXt6KXvG5mdyw2ll3HBaGRV1bp7buJ/ReekDTkH25pqTSrnvjZ3cs3QHf75u0RHn7a1rY3yMvhycN3M0B5o7OHfG4AcXF8wcw9s7anluw36eXFPV3Rbk4jljmd9LW5D7lllF8jedUT5oYxw/IotfXj6HEa40TpsyeNO14bpg5hg8Xj+fP70s7n3ehpqxETRsrWvtZHtNKx+bXxKvYQ06DcLUkFGUfXjFVSzaU6hjz4TCLG5eEnmwkJ2ewudOncQvXvmQTfuamFlyuBFoRb2bKTHawy4vM5Wvnp2YDuqZaU5+eflcfnKZj6Uf1PCf9dU8tqqSh97by5i8DC6cNYaL5oxlzrg8DjZ38viqSj65YFz3h+pguXRu8n8Qjx+RxZfPSlwn/GQ2Ji/8hq3BeszhUpQPGoSpISS04DcWdTdKReKzp07k/rd2cc/S7fzhMwsBaxPmyob2pJ0Wi0SwLciFs8fQ2unl1S0HeXZDNQ+9t4c/vr2b8SMyGZmdjs8Ybj4juk261bEnI9VJUXYa+xrt14Qt31VPRqqDWSX58RvYINMgTA0ZWWlOMlIddHT5NQhTCZObkcp/nTqJ37y2nQ8ONDNtdG73Kq/hmqENtgW5bF4JTe4uXtpygGc37OedHbVcvnBc1L3R1LEp3F5hK3fXM39CQVTbgiWb4fNI1LAnIhS6rGxYLHqEKRWp60+daG0ovdTaUDqWKyOTXWhbkPV3nMuPLp2Z6CGpIWpsnv0grMndxdYDzZw4DLYqCqVBmBpSgnVh4wqG/4edSl75WWlce8pEntu4nx01rcdUEBYqOz1l2KxSU4MvmAmzs8vF6r31GAMnDKN6MNAgTA0xhdnp5KfLoPdOUqqnGxZPIiPFye9e30FFvRuHHF52r5Qa2Nj8DNo8PprbvX1epqPLxwsb9/Pb13eQ5nQwb0L+4A1wEGhNmBpSrj91EmWpjYkehlIUZqfz6RMn8Od3djN3fD5j8jKHVa2KUvEW2issL6S/XqfXx1sf1vLshmpe2XKQNo+Pouw0brtgGhmpw+sLuAZhakhZPKUI777om2EqFQs3nl7Gw8v3sraikZPLhletilLxFtorbMqobN7dWcez66t5cfMBWjq85GelcvGcsVw8ZywnThoxLKe+NQhTSqkIFedmcNUJE/jLu3uOuXowpaJVUmAFYb9Zup1vPbmeBncXOekpnDNjFBfPGcviyUXDvsmtBmFKKRWFL5xRxuOrKpk2JjaNWpU6VhS60ijKTmNHTStnHz+Ki2eP4fSpI4fdlGN/NAhTSqkojMnL5J3bziI3Q99OlQqHiPDK188gI9V5zC620ncNpZSK0ghX2sAXUkodpeAY/9sZ3pOtSimllFJJSoMwpZRSSqkE0CBMKaWUUioBNAhTSimllEoADcKUUkoppRJAgzCllFJKqQTQIEwppZRSKgE0CFNKKaWUSgANwpRSSimlEkCDMKWUUkqpBBBjTKLHEBYROQTsHYS7KgJqB+F+VPj02CQ3PT7JS49NctPjk7yiOTalxpiRvZ0x5IKwwSIiq40xCxM9DnU0PTbJTY9P8tJjk9z0+CSveB0bnY5USimllEoADcKUUkoppRJAg7C+3Z/oAag+6bFJbnp8kpcem+Smxyd5xeXYaE2YUkoppVQCaCZMKaWUUioBNAjrQUTOF5FtIrJDRG5L9HiOdSLyZxGpEZFNIaeNEJFXRGR74P+CRI7xWCUi40XkdRHZKiKbReSWwOl6fBJMRDJEZKWIrA8cmzsDp+uxSSIi4hSR90Xk2cDvenyShIjsEZGNIrJORFYHTov58dEgLISIOIF7gQuA6cBVIjI9saM65v0FOL/HabcBrxljpgCvBX5Xg88LfNMYczxwEvClwN+LHp/E6wTOMsbMAeYC54vISeixSTa3AFtDftfjk1zONMbMDWlNEfPjo0HYkU4AdhhjdhljPMBjwKUJHtMxzRjzJlDf4+RLgYcCPz8EXDaYY1IWY8x+Y8zawM8tWB8mJejxSThjaQ38mhr4Z9BjkzREZBxwIfDHkJP1+CS3mB8fDcKOVAJUhvxeFThNJZdRxpj9YAUCQHGCx3PME5GJwDxgBXp8kkJgqmsdUAO8YozRY5Ncfg18G/CHnKbHJ3kY4GURWSMiNwZOi/nxSYn2BoYZ6eU0XT6qVD9EJBt4CviaMaZZpLc/IzXYjDE+YK6I5ANPi8jMBA9JBYjIRUCNMWaNiCxJ8HBU7041xlSLSDHwioh8EI870UzYkaqA8SG/jwOqEzQW1beDIjIGIPB/TYLHc8wSkVSsAOwRY8w/Ayfr8UkixphGYBlWbaUem+RwKnCJiOzBKns5S0T+hh6fpGGMqQ78XwM8jVWuFPPjo0HYkVYBU0RkkoikAVcCzyR4TOpozwCfDfz8WeDfCRzLMUuslNefgK3GmF+GnKXHJ8FEZGQgA4aIZAIfAT5Aj01SMMZ81xgzzhgzEetzZqkx5hr0+CQFEXGJSE7wZ+BcYBNxOD7arLUHEfko1ly9E/izMeYniR3RsU1E/g4swdrB/iBwB/Av4AlgAlABfMoY07N4X8WZiCwG3gI2criu5XtYdWF6fBJIRGZjFQ47sb5sP2GMuUtECtFjk1QC05G3GmMu0uOTHESkDCv7BVbZ1qPGmJ/E4/hoEKaUUkoplQA6HamUUkoplQAahCmllFJKJYAGYUoppZRSCaBBmFJKKaVUAmgQppRSSimVABqEKaWGNBHxici6kH/9bqorIjeJyLUxuN89IlIU7e0opY5d2qJCKTWkiUirMSY7Afe7B1hojKkd7PtWSg0PmglTSg1LgUzVz0VkZeDf5MDpPxSRWwM/f1VEtojIBhF5LHDaCBH5V+C05YHGp4hIoYi8LCLvi8gfCNlrVkSuCdzHOhH5g4g4E/CQlVJDjAZhSqmhLrPHdOQVIec1G2NOAH6LtRNGT7cB84wxs4GbAqfdCbwfOO17wF8Dp98BvG2MmYe1fckEABE5HrgCa8PfuYAP+HQsH6BSanhKSfQAlFIqSu2B4Kc3fw/5/1e9nL8BeERE/oW1HRbAYuATAMaYpYEMWB5wOvDxwOnPiUhD4PJnAwuAVdZ2mmSiGy8rpWzQIEwpNZyZPn4OuhAruLoE+IGIzCBkmrGX6/Z2GwI8ZIz5bjQDVUode3Q6Uik1nF0R8v97oWeIiAMYb4x5Hfg2kA9kA28SmE4MbK5ca4xp7nH6BUBB4KZeAz4pIsWB80aISGncHpFSatjQTJhSaqjLFJF1Ib+/aIwJtqlIF5EVWF84r+pxPSfwt8BUowC/MsY0isgPgQdFZAPgBj4buPydwN9FZC3wBlABYIzZIiLfB14OBHZdwJeAvTF+nEqpYUZbVCilhiVtIaGUSnY6HamUUkoplQCaCVNKKaWUSgDNhCmllFJKJYAGYUoppZRSCaBBmFJKKaVUAmgQppRSSimVABqEKaWUUkolgAZhSimllFIJ8P8BZxZMoSh2aboAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot and label the curve with mean over all experiments for each episode for uniformly random policy\n",
    "#all in one plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(np.mean(rewards_uf[:,:], axis=0), label='Uniform random returns')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average Return per experiment')\n",
    "plt.title('Uniform random returns gathered 500 episodes')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(14, 4)\n",
      "14\n",
      "(4,)\n",
      "[array([0., 0., 0., ..., 0., 0., 0.]) array(1)\n",
      " array([0., 0., 0., ..., 0., 0., 0.]) array(1.)]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#print the shape of the expert data for uniformly random policy\n",
    "print(expert_data_uf.shape) # number of episodes\n",
    "print(expert_data_uf[0].shape) # number of steps in first episode\n",
    "print(expert_data_uf[0].shape[0]) # number of steps in first episode\n",
    "print(expert_data_uf[0][0].shape) # shape of first step S_t, A_t, S_t+1, R_t\n",
    "print(expert_data_uf[0][0]) # first step values S_t, A_t, S_t+1, R_t\n",
    "print(expert_data_uf[0][0][0]) # first step values S_t\n",
    "print(expert_data_uf[0][0][1]) # first step values A_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(episode_count)\n",
    "print(expert_data_ac.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[216, 91, 438, 231, 202, 128, 287, 336, 174, 371, 18, 456, 332, 11, 497, 404, 427, 245, 429, 378, 483, 433, 278, 44, 241, 53, 49, 400, 338, 381, 64, 446, 210, 268, 57, 444, 474, 80, 52, 488, 28, 301, 33, 246, 424, 321, 471, 213, 290, 254, 224, 177, 282, 386, 459, 150, 264, 192, 350, 298, 74, 205, 316, 51, 8, 486, 72, 185, 170, 106, 411, 306, 256, 60, 188, 73, 360, 284, 131, 85, 469, 481, 227, 5, 496, 16, 364, 1, 38, 168, 468, 116, 391, 439, 396, 36, 76, 67, 274, 134, 374, 260, 408, 195, 189, 113, 135, 366, 161, 392, 138, 349, 40, 24, 187, 354, 234, 251, 221, 34, 58, 440, 184, 289, 149, 95, 437, 385, 297, 211, 325, 270, 103, 56, 472, 395, 4, 418, 401, 250, 143, 190, 104, 252, 21, 48, 347, 414, 269, 329, 272, 193, 66, 372, 375, 380, 46, 83, 257, 7, 413, 484, 156, 410, 327, 198, 399, 71, 482, 303, 82, 363, 353, 182, 308, 123, 137, 157, 281, 166, 463, 45, 111, 382, 181, 117, 357, 92, 110, 229, 394, 430, 307, 87, 165, 267, 17, 370, 361, 415, 136, 88, 255, 200, 247, 203, 30, 451, 457, 175, 328, 487, 178, 409, 365, 462, 416, 495, 449, 499, 50, 235, 398, 96, 173, 147, 348, 6, 148, 27, 79, 470, 453, 293, 485, 183, 191, 318, 432, 448, 94, 420, 288, 262, 119, 498, 417, 144, 29, 333, 121, 323, 61, 476, 159, 311, 102, 442, 15, 20, 466, 114, 179, 26, 9, 240, 330, 129, 314, 142, 331, 292, 302, 232, 108, 452, 309, 133, 458, 93, 236, 69, 219, 42, 359, 201, 13, 273, 447, 239, 84, 436, 172, 358, 14, 342, 480, 334, 300, 249, 494, 279, 475, 214, 355, 152, 180, 3, 244, 443, 387, 10, 299, 199, 445, 105, 31, 388, 423, 277, 464, 208, 389, 32, 419, 78, 441, 118, 77, 70, 41, 276, 163, 405, 139, 428, 431, 39, 225, 140, 122, 320, 248, 478, 141, 326, 126, 132, 230, 393, 81, 228, 435, 218, 258, 313, 421, 162, 304, 286, 271, 454, 369, 68, 390, 62, 127, 285, 25, 237, 265, 403, 90, 112, 217, 54, 2, 352, 425, 397, 124, 204, 253, 196, 450, 367, 99, 294, 322, 212, 233, 37, 312, 243, 125, 23, 12, 75, 101, 115, 455, 344, 120, 384, 47, 171, 317, 324, 461, 263, 145, 43, 337, 86, 376, 407, 406, 242, 489, 109, 345, 422, 226, 238, 164, 335, 490, 296, 493, 467, 107, 146, 155, 479, 426, 280, 207, 154, 291, 315, 89, 383, 346, 194, 465, 215, 98, 65, 283, 151, 356, 206, 167, 209, 341, 158, 259, 153, 477, 63, 434, 339, 492, 319, 169, 340, 35, 220, 186, 100, 343, 377, 379, 368, 351, 275, 412, 473, 266, 0, 491, 362, 22, 130, 97, 295, 460, 197, 59, 261, 310, 223, 160, 402, 373, 176, 222, 305, 55, 19]\n"
     ]
    }
   ],
   "source": [
    "#randomly select half of the indices from expert_data_ac and half of the indices from expert_data_uf episodes\n",
    "#from a list of indices length of episodes\n",
    "indices = list(range(episode_count))\n",
    "random.shuffle(indices)\n",
    "print(indices)\n",
    "\n",
    "#select half of the indices from expert_data_ac and half of the indices from expert_data_uf episodes\n",
    "#combine them in a new array called expert_data_ac_uf\n",
    "expert_data_ac_uf = np.empty((episode_count), dtype=object)\n",
    "for i in range(episode_count):\n",
    "    if i < episode_count/2:\n",
    "        expert_data_ac_uf[indices[i]] = expert_data_ac[indices[i]]\n",
    "    else:\n",
    "        expert_data_ac_uf[indices[i]] = expert_data_uf[indices[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(33, 4)\n",
      "14\n",
      "(4,)\n",
      "[array([0., 0., 0., ..., 0., 0., 0.]) array(1)\n",
      " array([0., 0., 0., ..., 0., 0., 0.]) array(1.)]\n",
      "(10000,)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "expert_data_ac_uf = np.array(expert_data_ac_uf).squeeze() #with one experiment use squeeze\n",
    "\n",
    "#print the shape of the expert data for actor critic and uniformly random policy\n",
    "print(expert_data_ac_uf.shape) # number of episodes\n",
    "print(expert_data_ac_uf[305].shape) # number of steps in first episode\n",
    "print(expert_data_ac_uf[0].shape[0]) # number of steps in first episode\n",
    "print(expert_data_ac_uf[0][0].shape) # shape of first step S_t, A_t, S_t+1, R_t\n",
    "print(expert_data_ac_uf[0][0]) # first step values S_t, A_t, S_t+1, R_t\n",
    "print(expert_data_ac_uf[0][0][0].shape) # first step values S_t\n",
    "print(expert_data_ac_uf[0][0][1]) # first step values A_t\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline RL\n",
    "Using expert data\n",
    "A2C: expert_data_ac\n",
    "Uniform random: expert_data_uf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters for training\n",
    "episode_cs = [100, 250, 500] #number of episode sizes to select from in each experiment\n",
    "alphas = [1/8, 1/16] #learning rates \n",
    "gamma = 0.99 #discount factor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple imitation learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Offline training using expert data on a policy network model (supervised)\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "#use encoder to discretize the state space\n",
    "oh = OneHotFA(env, bins)\n",
    "\n",
    "# Initialize a table to count the rewards for each episode\n",
    "rewards = np.zeros(episode_count)\n",
    "# Initialize a table to count the number of steps for each episode\n",
    "steps = np.zeros(episode_count)\n",
    "\n",
    "# Loop over episodes\n",
    "for ep_step in tqdm(range(episode_count)):\n",
    "    # get first state and action for current episode\n",
    "    state_discrete = expert_data_ac[0][0][0]\n",
    "    first_action = expert_data_ac[0][0][1]\n",
    "    # state_discrete, _ = oh.discretize_state(state) #already discretized\n",
    "    truncated = False\n",
    "    terminated = False\n",
    "    episode_memory = []\n",
    "\n",
    "    # Loop over time steps within the episode\n",
    "    while not (terminated or truncated):\n",
    "        # Choose the next action using policy network #TODO use imitation learning (supervised learning)\n",
    "        action = oh.get_softmax_action(state_discrete, temperature = 0.01)\n",
    "\n",
    "        # Take the chosen action and observe the next state and reward\n",
    "        # next_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        # Get the previous action, next state and reward from expert data\n",
    "        expert_previous_action = expert_data_ac[0][steps[ep_step]][1]\n",
    "        next_state_discrete = expert_data_ac[0][steps[ep_step]][2]\n",
    "        reward = expert_data_ac[0][steps[ep_step]][3]\n",
    "\n",
    "        #terminated set to true if the step size is equal to\n",
    "        if steps[ep_step] == expert_data_ac[0].shape[0] - 1:\n",
    "            terminated = True\n",
    "\n",
    "        # Discretize the next state\n",
    "        #next_state_discrete, next_state_index = oh.discretize_state(next_state)\n",
    "\n",
    "        episode_memory.append((state_discrete, action, reward, next_state_discrete))\n",
    "\n",
    "        # Update the state TODO need?\n",
    "        state_discrete = next_state_discrete\n",
    "\n",
    "        # store the total reward for each episode\n",
    "        rewards[ep_step] += rewards * (gamma ** steps[ep_step])\n",
    "        # store the number of steps for each episode\n",
    "        steps[ep_step] += 1\n",
    "\n",
    "        env.render()\n",
    "\n",
    "\n",
    "\n",
    "    #TODO Update using imitation learning after each episode use\n",
    "    for t in range(len(episode_memory)):\n",
    "        state_discrete, action, reward, next_state_discrete = episode_memory[t]\n",
    "        state_index = np.argmax(state_discrete)\n",
    "        next_state_index = np.argmax(next_state_discrete)\n",
    "\n",
    "        #TODO\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print and plot the average rewards (return) with its standard deviation for all episodes\n",
    "print(\"Average reward: \", np.mean(rewards))\n",
    "print(\"Standard deviation: \", np.std(rewards))\n",
    "plt.plot(rewards)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online greedy test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#online greedy testing parameters\n",
    "episode_count = 100\n",
    "rewards_il = np.zeros((experiment_count, episode_count))\n",
    "\n",
    "\n",
    "#A2C agent #TODO use imitation learning agent weights\n",
    "QFunction = agent.actor[0].weight.data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#initialize the environment\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "#use encoder to discretize the state space\n",
    "oha = OneHotFA(env, bins)\n",
    "\n",
    "# Initialize a table to count the rewards for each episode\n",
    "rewards_each_ep = np.zeros(episode_count)\n",
    "episode_data = []\n",
    "expert_data_il = []\n",
    "\n",
    "# Initialize a table to count the number of steps for each episode\n",
    "steps = np.zeros(episode_count)\n",
    "\n",
    "# Loop over episodes\n",
    "for ep in range(episode_count):\n",
    "    # initialize state and action for current episode\n",
    "    state, info = env.reset(seed=seed) \n",
    "    state_discrete, state_index = ofa.discretize_state(state)\n",
    "    truncated = False\n",
    "    terminated = False\n",
    "    \n",
    "    episode_memory = []\n",
    "    \n",
    "    # Loop over time steps within the episode\n",
    "    while not (terminated or truncated):\n",
    "\n",
    "        # Choose the next action using greedy policy\n",
    "        action = epsilon_greedy(QFunction, state_discrete, num_actions=num_actions, epsilon=0.0)\n",
    "        # Take the chosen action and observe the next state and reward\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        # Discretize the next state\n",
    "        next_state_discrete, next_state_index = ofa.discretize_state(next_state)\n",
    "\n",
    "        episode_memory.append((state_discrete, np.asarray(action), next_state_discrete, np.asarray(reward)))\n",
    "\n",
    "        # Update the state\n",
    "        state_discrete = next_state_discrete\n",
    "\n",
    "        # store the total reward for each episode\n",
    "        rewards_each_ep[ep] += reward * (gamma ** step)\n",
    "\n",
    "        # store the number of steps for each episode\n",
    "        steps[ep] += 1\n",
    "\n",
    "        env.render()\n",
    "\n",
    "    episode_data.append(np.array(episode_memory))\n",
    "\n",
    "#save the rewards for each episode\n",
    "rewards_il[exp, :] = rewards_each_ep\n",
    "\n",
    "#save the episode data\n",
    "expert_data_il.append(np.array(episode_data))\n",
    "\n",
    "#close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the average rewards (return) with its standard deviation for all episodes\n",
    "print(\"Average reward: \", np.mean(rewards_il))\n",
    "print(\"Standard deviation: \", np.std(rewards_il))\n",
    "plt.plot(rewards_il)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitted Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO plots here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online greedy test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO plots here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline RL on CartPole v1 (with multi-layer perceptron) Offline Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Code similar to above\n",
    "#Modify class A2C(nn.Module) using multiple layers for state (non-binned) actor/critic input and action/value output "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (CartPole State Discretization Method) Sample CartPole environment velocities to calculate the bins discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "\n",
    "num_episodes = 100\n",
    "num_runs = 10\n",
    "seeds = [0, 137, 2, 3, 4, 42, 6, 7, 8, 9]\n",
    "\n",
    "cart_velocities = []\n",
    "pole_velocities = []\n",
    "for run in range(num_runs):\n",
    "    print(\"Run {}\".format(run))\n",
    "    cart_evm = []\n",
    "    pole_evm = []\n",
    "    for episode in range(num_episodes):\n",
    "        obs, info = env.reset(seed=seeds[run])\n",
    "        truncated = False\n",
    "        terminated = False\n",
    "        cart_ev = []\n",
    "        pole_ev = []\n",
    "        while not (truncated or terminated):\n",
    "            action = env.action_space.sample()\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            cart_ev.append(obs[1])\n",
    "            pole_ev.append(obs[3])\n",
    "            env.render()\n",
    "\n",
    "        cart_evm.append(np.mean(cart_ev))\n",
    "        pole_evm.append(np.mean(pole_ev))\n",
    "\n",
    "    cart_velocities.append(cart_evm)\n",
    "    pole_velocities.append(pole_evm)\n",
    "\n",
    "cart_velocities = np.array(cart_velocities)\n",
    "pole_velocities = np.array(pole_velocities)\n",
    "\n",
    "print(\"Mean velocity: {:.2f}\".format(np.mean(cart_velocities)))\n",
    "print(\"Variance of velocity: {:.2f}\".format(np.var(cart_velocities)))\n",
    "print(\"Minimum velocity: {:.2f}\".format(np.min(cart_velocities)))\n",
    "print(\"Maximum velocity: {:.2f}\".format(np.max(cart_velocities)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the histogram of the cart velocities \n",
    "c_mean_velocity = np.mean(cart_velocities)\n",
    "c_std_velocity = np.std(cart_velocities)\n",
    "\n",
    "# plot the histogram of the pole velocities\n",
    "p_mean_velocity = np.mean(pole_velocities)\n",
    "p_std_velocity = np.std(pole_velocities)\n",
    "\n",
    "# Define bins based on normal distribution of velocities for cart\n",
    "bins_c = [-np.inf]\n",
    "for i in range(1, 10):\n",
    "    bin_start = (i - 5) * c_std_velocity/2\n",
    "    bins_c.append(bin_start)\n",
    "bins_c.append(np.inf)\n",
    "# Create histogram of velocities\n",
    "hist, bin_edges = np.histogram(cart_velocities, bins=bins_c)\n",
    "print(\"Histogram of velocities:\")\n",
    "for i in range(len(hist)):\n",
    "    print(\"[{:.2f}, {:.2f}): {}\".format(bin_edges[i], bin_edges[i+1], hist[i]))\n",
    "\n",
    "# Define bins based on normal distribution of velocities for pole\n",
    "bins = [-np.inf]\n",
    "for i in range(1, 10):\n",
    "    bin_start = (i - 5) * p_std_velocity/2\n",
    "    bins.append(bin_start)\n",
    "bins.append(np.inf)\n",
    "# Create histogram of velocities\n",
    "hist, bin_edges = np.histogram(pole_velocities, bins=bins)\n",
    "print(\"Histogram of velocities:\")\n",
    "for i in range(len(hist)):\n",
    "    print(\"[{:.2f}, {:.2f}): {}\".format(bin_edges[i], bin_edges[i+1], hist[i]))\n",
    "\n",
    "print(bins_c)\n",
    "print(bins)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6034ab76b57820563a60aa78164bee995dd784ba7ae220cfd3293a276365bc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
